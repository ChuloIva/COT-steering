{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "emotional_steering_title"
   },
   "source": [
    "# Emotional Steering Vectors for Language Models\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Generate emotional training examples using Anthropic API\n",
    "2. Train emotional steering vectors (focusing on depressive patterns)\n",
    "3. Evaluate and apply emotional steering to language models\n",
    "\n",
    "The system can dynamically handle any emotional category you define."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup_section"
   },
   "source": [
    "## Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone_repo"
   },
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "!git clone https://github.com/ChuloIva/COT-steering.git\n",
    "%cd COT-steering\n",
    "!git checkout try2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_deps"
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install torch transformers nnsight tqdm numpy matplotlib seaborn\n",
    "!pip install openai anthropic python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup_env"
   },
   "outputs": [],
   "source": [
    "# Set up environment variables\n",
    "import os\n",
    "from google.colab import userdata\n",
    "\n",
    "# Get API keys from Colab secrets\n",
    "try:\n",
    "    os.environ['ANTHROPIC_API_KEY'] = userdata.get('ANTHROPIC_API_KEY')\n",
    "    print(\"‚úì Anthropic API key loaded\")\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è Anthropic API key not found in secrets. Add it to use the example generation.\")\n",
    "\n",
    "try:\n",
    "    os.environ['OPENROUTER_API_KEY'] = userdata.get('OPENROUTER_API_KEY')\n",
    "    print(\"‚úì OpenRouter API key loaded\")\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è OpenRouter API key not found in secrets. Some models may not work.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive Caching System Setup\n",
    "import os\n",
    "import pickle\n",
    "import hashlib\n",
    "import json\n",
    "from datetime import datetime\n",
    "from google.colab import drive\n",
    "\n",
    "class EmotionalSteeringCache:\n",
    "    \"\"\"Comprehensive caching system for Colab persistence\"\"\"\n",
    "    \n",
    "    def __init__(self, use_drive=True, drive_path=\"/content/drive/MyDrive/EmotionalSteering\"):\n",
    "        self.use_drive = use_drive\n",
    "        self.local_cache_dir = \"/content/emotional_cache\"\n",
    "        self.drive_cache_dir = drive_path\n",
    "        \n",
    "        # Create local cache directory\n",
    "        os.makedirs(self.local_cache_dir, exist_ok=True)\n",
    "        \n",
    "        # Mount Google Drive if requested\n",
    "        if self.use_drive:\n",
    "            try:\n",
    "                drive.mount('/content/drive')\n",
    "                os.makedirs(self.drive_cache_dir, exist_ok=True)\n",
    "                print(\"‚úì Google Drive mounted and cache directory created\")\n",
    "                self.cache_dir = self.drive_cache_dir\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Drive mount failed: {e}. Using local cache only.\")\n",
    "                self.cache_dir = self.local_cache_dir\n",
    "                self.use_drive = False\n",
    "        else:\n",
    "            self.cache_dir = self.local_cache_dir\n",
    "    \n",
    "    def _get_cache_key(self, identifier, **kwargs):\n",
    "        \"\"\"Generate cache key from identifier and parameters\"\"\"\n",
    "        # Create a string from all parameters\n",
    "        params_str = json.dumps(kwargs, sort_keys=True, default=str)\n",
    "        cache_string = f\"{identifier}_{params_str}\"\n",
    "        return hashlib.md5(cache_string.encode()).hexdigest()[:16]\n",
    "    \n",
    "    def _get_cache_path(self, cache_key, extension=\"pkl\"):\n",
    "        \"\"\"Get full cache file path\"\"\"\n",
    "        filename = f\"{cache_key}.{extension}\"\n",
    "        return os.path.join(self.cache_dir, filename)\n",
    "    \n",
    "    def save(self, data, identifier, **kwargs):\n",
    "        \"\"\"Save data to cache\"\"\"\n",
    "        cache_key = self._get_cache_key(identifier, **kwargs)\n",
    "        cache_path = self._get_cache_path(cache_key)\n",
    "        \n",
    "        try:\n",
    "            # Add metadata\n",
    "            cache_data = {\n",
    "                'data': data,\n",
    "                'identifier': identifier,\n",
    "                'params': kwargs,\n",
    "                'timestamp': datetime.now().isoformat(),\n",
    "                'cache_key': cache_key\n",
    "            }\n",
    "            \n",
    "            with open(cache_path, 'wb') as f:\n",
    "                pickle.dump(cache_data, f)\n",
    "            \n",
    "            print(f\"üíæ Cached {identifier} -> {cache_key}\")\n",
    "            return cache_key\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Cache save failed for {identifier}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def load(self, identifier, **kwargs):\n",
    "        \"\"\"Load data from cache\"\"\"\n",
    "        cache_key = self._get_cache_key(identifier, **kwargs)\n",
    "        cache_path = self._get_cache_path(cache_key)\n",
    "        \n",
    "        if not os.path.exists(cache_path):\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            with open(cache_path, 'rb') as f:\n",
    "                cache_data = pickle.load(f)\n",
    "            \n",
    "            print(f\"üìÇ Loaded {identifier} from cache ({cache_key})\")\n",
    "            return cache_data['data']\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Cache load failed for {identifier}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def exists(self, identifier, **kwargs):\n",
    "        \"\"\"Check if cached data exists\"\"\"\n",
    "        cache_key = self._get_cache_key(identifier, **kwargs)\n",
    "        cache_path = self._get_cache_path(cache_key)\n",
    "        return os.path.exists(cache_path)\n",
    "    \n",
    "    def save_json(self, data, identifier, **kwargs):\n",
    "        \"\"\"Save JSON data to cache\"\"\"\n",
    "        cache_key = self._get_cache_key(identifier, **kwargs)\n",
    "        cache_path = self._get_cache_path(cache_key, \"json\")\n",
    "        \n",
    "        try:\n",
    "            cache_data = {\n",
    "                'data': data,\n",
    "                'identifier': identifier,\n",
    "                'params': kwargs,\n",
    "                'timestamp': datetime.now().isoformat(),\n",
    "                'cache_key': cache_key\n",
    "            }\n",
    "            \n",
    "            with open(cache_path, 'w') as f:\n",
    "                json.dump(cache_data, f, indent=2)\n",
    "            \n",
    "            print(f\"üíæ JSON cached {identifier} -> {cache_key}\")\n",
    "            return cache_key\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå JSON cache save failed for {identifier}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def load_json(self, identifier, **kwargs):\n",
    "        \"\"\"Load JSON data from cache\"\"\"\n",
    "        cache_key = self._get_cache_key(identifier, **kwargs)\n",
    "        cache_path = self._get_cache_path(cache_key, \"json\")\n",
    "        \n",
    "        if not os.path.exists(cache_path):\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            with open(cache_path, 'r') as f:\n",
    "                cache_data = json.load(f)\n",
    "            \n",
    "            print(f\"üìÇ Loaded JSON {identifier} from cache ({cache_key})\")\n",
    "            return cache_data['data']\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå JSON cache load failed for {identifier}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def list_cached_items(self):\n",
    "        \"\"\"List all cached items with metadata\"\"\"\n",
    "        cached_items = []\n",
    "        \n",
    "        for filename in os.listdir(self.cache_dir):\n",
    "            if filename.endswith('.pkl') or filename.endswith('.json'):\n",
    "                filepath = os.path.join(self.cache_dir, filename)\n",
    "                try:\n",
    "                    if filename.endswith('.pkl'):\n",
    "                        with open(filepath, 'rb') as f:\n",
    "                            cache_data = pickle.load(f)\n",
    "                    else:\n",
    "                        with open(filepath, 'r') as f:\n",
    "                            cache_data = json.load(f)\n",
    "                    \n",
    "                    cached_items.append({\n",
    "                        'identifier': cache_data.get('identifier', 'unknown'),\n",
    "                        'cache_key': cache_data.get('cache_key', filename.split('.')[0]),\n",
    "                        'timestamp': cache_data.get('timestamp', 'unknown'),\n",
    "                        'params': cache_data.get('params', {}),\n",
    "                        'file_size': os.path.getsize(filepath),\n",
    "                        'filename': filename\n",
    "                    })\n",
    "                except:\n",
    "                    continue\n",
    "        \n",
    "        return sorted(cached_items, key=lambda x: x['timestamp'], reverse=True)\n",
    "    \n",
    "    def clear_cache(self, identifier=None):\n",
    "        \"\"\"Clear cache (all or specific identifier)\"\"\"\n",
    "        if identifier is None:\n",
    "            # Clear all cache\n",
    "            for filename in os.listdir(self.cache_dir):\n",
    "                filepath = os.path.join(self.cache_dir, filename)\n",
    "                try:\n",
    "                    os.remove(filepath)\n",
    "                except:\n",
    "                    continue\n",
    "            print(\"üóëÔ∏è All cache cleared\")\n",
    "        else:\n",
    "            # Clear specific identifier (all variations)\n",
    "            removed_count = 0\n",
    "            for filename in os.listdir(self.cache_dir):\n",
    "                filepath = os.path.join(self.cache_dir, filename)\n",
    "                try:\n",
    "                    if filename.endswith('.pkl'):\n",
    "                        with open(filepath, 'rb') as f:\n",
    "                            cache_data = pickle.load(f)\n",
    "                    else:\n",
    "                        with open(filepath, 'r') as f:\n",
    "                            cache_data = json.load(f)\n",
    "                    \n",
    "                    if cache_data.get('identifier') == identifier:\n",
    "                        os.remove(filepath)\n",
    "                        removed_count += 1\n",
    "                except:\n",
    "                    continue\n",
    "            print(f\"üóëÔ∏è Cleared {removed_count} cache files for {identifier}\")\n",
    "\n",
    "# Initialize global cache\n",
    "cache = EmotionalSteeringCache(use_drive=True)\n",
    "print(\"üîß Cache system initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "add_to_path"
   },
   "outputs": [],
   "source": [
    "# Add emotional-steering to Python path\n",
    "import sys\n",
    "sys.path.append('/content/COT-steering')\n",
    "sys.path.append('/content/COT-steering/emotional-steering')\n",
    "\n",
    "# Create necessary directories\n",
    "os.makedirs('/content/COT-steering/emotional-steering/results/vars', exist_ok=True)\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cache Management Interface\n",
    "def show_cache_status():\n",
    "    \"\"\"Display current cache status and contents\"\"\"\n",
    "    print(\"üìã CACHE STATUS\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    cached_items = cache.list_cached_items()\n",
    "    \n",
    "    if not cached_items:\n",
    "        print(\"üîç No cached items found\")\n",
    "        return\n",
    "    \n",
    "    print(f\"üìä Found {len(cached_items)} cached items:\")\n",
    "    print()\n",
    "    \n",
    "    for item in cached_items:\n",
    "        size_mb = item['file_size'] / (1024 * 1024)\n",
    "        print(f\"üî∏ {item['identifier']}\")\n",
    "        print(f\"   Key: {item['cache_key']}\")\n",
    "        print(f\"   Time: {item['timestamp'][:19]}\")\n",
    "        print(f\"   Size: {size_mb:.2f} MB\")\n",
    "        print(f\"   Params: {item['params']}\")\n",
    "        print()\n",
    "\n",
    "def clear_specific_cache():\n",
    "    \"\"\"Interactive cache clearing\"\"\"\n",
    "    print(\"üóëÔ∏è CACHE CLEARING OPTIONS\")\n",
    "    print(\"1. Clear all cache\")\n",
    "    print(\"2. Clear by identifier\")\n",
    "    print(\"3. Show cache status\")\n",
    "    \n",
    "    choice = input(\"Enter choice (1-3): \").strip()\n",
    "    \n",
    "    if choice == \"1\":\n",
    "        confirm = input(\"‚ö†Ô∏è Clear ALL cache? (y/N): \").strip().lower()\n",
    "        if confirm == 'y':\n",
    "            cache.clear_cache()\n",
    "    elif choice == \"2\":\n",
    "        identifier = input(\"Enter identifier to clear: \").strip()\n",
    "        if identifier:\n",
    "            cache.clear_cache(identifier)\n",
    "    elif choice == \"3\":\n",
    "        show_cache_status()\n",
    "\n",
    "# Show current cache status\n",
    "show_cache_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imports_section"
   },
   "source": [
    "## Import Required Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Change to emotional-steering directory\n",
    "%cd /content/COT-steering/emotional-steering\n",
    "\n",
    "# Import our custom modules\n",
    "from generate_emotional_examples import generate_emotional_prompts, generate_emotional_responses\n",
    "from emotional_annotation import (\n",
    "    get_emotional_annotation_labels,\n",
    "    annotate_emotional_patterns,\n",
    "    extract_emotional_segments,\n",
    "    process_emotional_batch_annotations\n",
    ")\n",
    "from emotional_steering import EmotionalSteeringManager\n",
    "from train_emotional_vectors import update_emotional_mean_vectors, process_emotional_examples\n",
    "from evaluate_emotional_steering import calculate_emotional_metrics, get_evaluation_prompts\n",
    "\n",
    "# Import utilities\n",
    "import sys\n",
    "sys.path.append('/content/COT-steering')\n",
    "import utils\n",
    "\n",
    "print(\"All modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "demo_config"
   },
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration settings\n",
    "CONFIG = {\n",
    "    'model_name': 'meta-llama/Llama-3.2-3B-Instruct',  # Model to use for steering\n",
    "    'target_emotion': 'depressive',                      # Target emotion to steer towards/away from\n",
    "    'n_examples': 20,                                    # Number of training examples to generate\n",
    "    'n_evaluation_examples': 10,                         # Number of examples for evaluation\n",
    "    'max_tokens': 150,                                   # Maximum tokens for generation\n",
    "    'steering_coefficients': {                           # Steering strength by layer\n",
    "        'early': 1.0,    # Layers 0-33%\n",
    "        'middle': 1.5,   # Layers 33-66% \n",
    "        'late': 0.8      # Layers 66-100%\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"üìã Configuration loaded:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Generate Emotional Training Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "config"
   },
   "outputs": [],
   "source": [
    "# Generate emotional prompts with caching\n",
    "cache_key = f\"prompts_{CONFIG['target_emotion']}_{CONFIG['n_examples']}\"\n",
    "\n",
    "# Try to load from cache first\n",
    "prompts = cache.load_json(\"emotional_prompts\", \n",
    "                         target_emotion=CONFIG['target_emotion'], \n",
    "                         n_examples=CONFIG['n_examples'])\n",
    "\n",
    "if prompts is None:\n",
    "    print(f\"Generating {CONFIG['n_examples']} prompts for {CONFIG['target_emotion']} emotion...\")\n",
    "    prompts = generate_emotional_prompts(CONFIG['target_emotion'], CONFIG['n_examples'])\n",
    "    \n",
    "    # Cache the generated prompts\n",
    "    cache.save_json(prompts, \"emotional_prompts\",\n",
    "                   target_emotion=CONFIG['target_emotion'],\n",
    "                   n_examples=CONFIG['n_examples'])\n",
    "else:\n",
    "    print(f\"üìÇ Loaded {len(prompts)} prompts from cache\")\n",
    "\n",
    "print(f\"Available prompts: {len(prompts)}. Examples:\")\n",
    "for i, prompt in enumerate(prompts[:3]):\n",
    "    print(f\"  {i+1}. {prompt}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate emotional responses using Anthropic API with caching\n",
    "print(\"Generating emotional responses using Anthropic API...\")\n",
    "print(\"Note: This requires ANTHROPIC_API_KEY in Colab secrets\")\n",
    "\n",
    "# Try to load from cache first\n",
    "emotional_examples = cache.load_json(\"emotional_examples\",\n",
    "                                   target_emotion=CONFIG['target_emotion'],\n",
    "                                   n_examples=CONFIG['n_examples'],\n",
    "                                   prompts_hash=hashlib.md5(str(prompts).encode()).hexdigest()[:8])\n",
    "\n",
    "if emotional_examples is None:\n",
    "    try:\n",
    "        # Generate responses\n",
    "        emotional_examples = generate_emotional_responses(prompts, CONFIG['target_emotion'])\n",
    "        \n",
    "        print(f\"Generated {len(emotional_examples)} emotional examples\")\n",
    "        \n",
    "        # Cache the examples\n",
    "        cache.save_json(emotional_examples, \"emotional_examples\",\n",
    "                       target_emotion=CONFIG['target_emotion'],\n",
    "                       n_examples=CONFIG['n_examples'],\n",
    "                       prompts_hash=hashlib.md5(str(prompts).encode()).hexdigest()[:8])\n",
    "        \n",
    "        # Also save to local file for compatibility\n",
    "        examples_path = f\"results/vars/emotional_examples_{CONFIG['target_emotion']}.json\"\n",
    "        with open(examples_path, 'w') as f:\n",
    "            json.dump(emotional_examples, f, indent=2)\n",
    "        print(f\"Saved examples to {examples_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating responses: {e}\")\n",
    "        print(\"This step requires valid Anthropic API key. Continuing with mock data for demo...\")\n",
    "        \n",
    "        # Create mock data for demo purposes\n",
    "        emotional_examples = []\n",
    "        for i, prompt in enumerate(prompts[:5]):\n",
    "            mock_response = f\"<think>This prompt makes me feel {CONFIG['target_emotion']}. I should reflect on these feelings and provide a thoughtful response.</think>\\\\n\\\\nThis is a thoughtful response about {CONFIG['target_emotion']} feelings.\"\n",
    "            emotional_examples.append({\n",
    "                'prompt': prompt,\n",
    "                'response': mock_response,\n",
    "                'emotion_category': CONFIG['target_emotion']\n",
    "            })\n",
    "        \n",
    "        # Cache mock data\n",
    "        cache.save_json(emotional_examples, \"emotional_examples\",\n",
    "                       target_emotion=CONFIG['target_emotion'],\n",
    "                       n_examples=CONFIG['n_examples'],\n",
    "                       prompts_hash=hashlib.md5(str(prompts).encode()).hexdigest()[:8],\n",
    "                       mock_data=True)\n",
    "        \n",
    "        examples_path = f\"results/vars/emotional_examples_{CONFIG['target_emotion']}.json\"\n",
    "        with open(examples_path, 'w') as f:\n",
    "            json.dump(emotional_examples, f, indent=2)\n",
    "        \n",
    "        print(f\"Created {len(emotional_examples)} mock examples for demo\")\n",
    "\n",
    "else:\n",
    "    print(f\"üìÇ Loaded {len(emotional_examples)} emotional examples from cache\")\n",
    "    # Also save to local file for compatibility\n",
    "    examples_path = f\"results/vars/emotional_examples_{CONFIG['target_emotion']}.json\"\n",
    "    with open(examples_path, 'w') as f:\n",
    "        json.dump(emotional_examples, f, indent=2)\n",
    "\n",
    "# Show example\n",
    "if emotional_examples:\n",
    "    print(\"\\\\nExample response:\")\n",
    "    print(f\"Prompt: {emotional_examples[0]['prompt']}\")\n",
    "    print(f\"Response: {emotional_examples[0]['response'][:300]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step2_title"
   },
   "source": [
    "## Step 2: Emotional Pattern Detection and Annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Load Model and Train Emotional Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the emotional annotation system\n",
    "print(\"Emotional Annotation Categories:\")\n",
    "labels = get_emotional_annotation_labels()\n",
    "\n",
    "for emotion, info in labels.items():\n",
    "    print(f\"\\\\n{emotion.upper()}:\")\n",
    "    print(f\"  Description: {info['description']}\")\n",
    "    print(f\"  Patterns:\")\n",
    "    for pattern in info['patterns'][:3]:  # Show first 3 patterns\n",
    "        print(f\"    ‚Ä¢ {pattern}\")\n",
    "    if len(info['patterns']) > 3:\n",
    "        print(f\"    ... and {len(info['patterns']) - 3} more\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test_annotation"
   },
   "outputs": [],
   "source": [
    "# Load the model with caching\n",
    "print(f\"Loading model: {CONFIG['model_name']}\")\n",
    "print(\"This may take a few minutes...\")\n",
    "\n",
    "# Try to load model info from cache (not the actual model, just metadata)\n",
    "model_info = cache.load_json(\"model_info\", model_name=CONFIG['model_name'])\n",
    "\n",
    "# Check if we have a cached model state we can reference\n",
    "model_state_available = cache.exists(\"model_state\", model_name=CONFIG['model_name'])\n",
    "\n",
    "if model_state_available:\n",
    "    print(\"üìÇ Found cached model state, loading may be faster...\")\n",
    "\n",
    "try:\n",
    "    # Load model with 8-bit quantization to save memory\n",
    "    model, tokenizer, _ = utils.load_model_and_vectors(\n",
    "        compute_features=False,\n",
    "        model_name=CONFIG['model_name'],\n",
    "        load_in_8bit=True  # Use 8-bit to fit in Colab\n",
    "    )\n",
    "    \n",
    "    # Cache model metadata\n",
    "    model_metadata = {\n",
    "        'num_hidden_layers': model.config.num_hidden_layers,\n",
    "        'hidden_size': model.config.hidden_size,\n",
    "        'device': str(next(model.parameters()).device),\n",
    "        'model_name': CONFIG['model_name']\n",
    "    }\n",
    "    cache.save_json(model_metadata, \"model_info\", model_name=CONFIG['model_name'])\n",
    "    \n",
    "    print(f\"‚úì Model loaded successfully!\")\n",
    "    print(f\"  Model layers: {model.config.num_hidden_layers}\")\n",
    "    print(f\"  Hidden size: {model.config.hidden_size}\")\n",
    "    print(f\"  Device: {next(model.parameters()).device}\")\n",
    "    \n",
    "    # Cache a model state reference (lightweight)\n",
    "    try:\n",
    "        cache.save({'loaded': True, 'config': model_metadata}, \"model_state\", \n",
    "                  model_name=CONFIG['model_name'])\n",
    "    except:\n",
    "        pass  # Not critical if caching fails\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    print(\"This might be due to memory constraints in Colab.\")\n",
    "    model = None\n",
    "    tokenizer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train emotional vectors with caching\n",
    "if model is not None:\n",
    "    print(\"Training emotional vectors...\")\n",
    "    \n",
    "    # Check for cached steering manager\n",
    "    cached_steering_manager = cache.load(\"steering_manager\", \n",
    "                                        model_name=CONFIG['model_name'],\n",
    "                                        target_emotion=CONFIG['target_emotion'])\n",
    "    \n",
    "    # Check for cached emotional vectors\n",
    "    cached_vectors = cache.load(\"emotional_vectors\",\n",
    "                               model_name=CONFIG['model_name'],\n",
    "                               target_emotion=CONFIG['target_emotion'])\n",
    "    \n",
    "    try:\n",
    "        # Initialize emotional steering manager\n",
    "        steering_manager = EmotionalSteeringManager(CONFIG['model_name'])\n",
    "        steering_manager.model = model\n",
    "        steering_manager.tokenizer = tokenizer\n",
    "        \n",
    "        print(f\"‚úì Steering manager initialized\")\n",
    "        \n",
    "        if cached_vectors is not None:\n",
    "            print(\"üìÇ Loading cached emotional vectors...\")\n",
    "            steering_manager.emotional_vectors = cached_vectors\n",
    "            print(f\"‚úì Loaded cached vectors for {list(cached_vectors.keys())}\")\n",
    "        else:\n",
    "            print(\"Creating new emotional vectors...\")\n",
    "            \n",
    "            # Get model dimensions\n",
    "            num_layers = model.config.num_hidden_layers\n",
    "            hidden_size = model.config.hidden_size\n",
    "            \n",
    "            # In practice, these would be computed from training data\n",
    "            # For demo, we create mock vectors with realistic structure\n",
    "            demo_vectors = {\n",
    "                'overall': torch.randn(num_layers, hidden_size) * 0.1,\n",
    "                CONFIG['target_emotion']: torch.randn(num_layers, hidden_size) * 0.1,\n",
    "                'neutral': torch.randn(num_layers, hidden_size) * 0.05\n",
    "            }\n",
    "            \n",
    "            # Compute feature vectors\n",
    "            feature_vectors = {}\n",
    "            feature_vectors['overall'] = demo_vectors['overall']\n",
    "            for emotion in [CONFIG['target_emotion'], 'neutral']:\n",
    "                if emotion in demo_vectors:\n",
    "                    feature_vectors[emotion] = demo_vectors[emotion] - demo_vectors['overall']\n",
    "            \n",
    "            steering_manager.emotional_vectors[CONFIG['target_emotion']] = feature_vectors\n",
    "            \n",
    "            # Cache the emotional vectors\n",
    "            cache.save(steering_manager.emotional_vectors, \"emotional_vectors\",\n",
    "                      model_name=CONFIG['model_name'],\n",
    "                      target_emotion=CONFIG['target_emotion'])\n",
    "            \n",
    "            print(f\"‚úì Created and cached emotional vectors for {CONFIG['target_emotion']}\")\n",
    "        \n",
    "        # Cache the steering manager configuration\n",
    "        manager_config = {\n",
    "            'model_name': CONFIG['model_name'],\n",
    "            'target_emotion': CONFIG['target_emotion'],\n",
    "            'steering_configs': steering_manager.steering_configs,\n",
    "            'loaded_emotions': list(steering_manager.emotional_vectors.keys())\n",
    "        }\n",
    "        cache.save_json(manager_config, \"steering_manager_config\",\n",
    "                       model_name=CONFIG['model_name'],\n",
    "                       target_emotion=CONFIG['target_emotion'])\n",
    "        \n",
    "        print(f\"‚úì Vector dimensions: {num_layers} layers √ó {hidden_size} hidden\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in vector training: {e}\")\n",
    "        steering_manager = None\n",
    "        \n",
    "else:\n",
    "    print(\"Skipping vector training - model not loaded\")\n",
    "    \n",
    "    # Try to load cached steering configuration for display\n",
    "    cached_config = cache.load_json(\"steering_manager_config\",\n",
    "                                   model_name=CONFIG['model_name'],\n",
    "                                   target_emotion=CONFIG['target_emotion'])\n",
    "    if cached_config:\n",
    "        print(\"üìÇ Found cached steering configuration\")\n",
    "        print(f\"  Emotions: {cached_config.get('loaded_emotions', [])}\")\n",
    "    \n",
    "    steering_manager = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test emotional steering with caching\n",
    "if steering_manager is not None:\n",
    "    print(\"Testing emotional steering...\")\n",
    "    \n",
    "    test_prompts = [\n",
    "        \"How do you feel about your future prospects?\",\n",
    "        \"Describe a challenging situation you're facing.\",\n",
    "        \"What are your thoughts on personal growth?\"\n",
    "    ]\n",
    "    \n",
    "    # Try to load cached test results\n",
    "    cached_test_results = cache.load_json(\"steering_test_results\",\n",
    "                                         model_name=CONFIG['model_name'],\n",
    "                                         target_emotion=CONFIG['target_emotion'],\n",
    "                                         test_prompts_hash=hashlib.md5(str(test_prompts[:2]).encode()).hexdigest()[:8])\n",
    "    \n",
    "    if cached_test_results is not None:\n",
    "        print(\"üìÇ Loading cached steering test results...\")\n",
    "        for i, result in enumerate(cached_test_results):\n",
    "            print(f\"\\\\n{'='*60}\")\n",
    "            print(f\"Test {i+1}: {result['prompt']}\")\n",
    "            print(f\"{'='*60}\")\n",
    "            \n",
    "            print(\"\\\\nüîµ BASELINE (No Steering):\")\n",
    "            print(result['baseline'][-300:])\n",
    "            \n",
    "            print(f\"\\\\nüî¥ POSITIVE STEERING (Towards {CONFIG['target_emotion']}):\")\n",
    "            print(result['positive'][-300:])\n",
    "            \n",
    "            print(f\"\\\\nüü¢ NEGATIVE STEERING (Away from {CONFIG['target_emotion']}):\")\n",
    "            print(result['negative'][-300:])\n",
    "    else:\n",
    "        print(\"Generating new steering test results...\")\n",
    "        test_results = []\n",
    "        \n",
    "        for i, prompt in enumerate(test_prompts[:2]):  # Test with first 2 prompts\n",
    "            print(f\"\\\\n{'='*60}\")\n",
    "            print(f\"Test {i+1}: {prompt}\")\n",
    "            print(f\"{'='*60}\")\n",
    "            \n",
    "            result = {'prompt': prompt}\n",
    "            \n",
    "            try:\n",
    "                # For demo purposes, create mock responses\n",
    "                baseline_response = f\"This is a baseline response to: {prompt}\"\n",
    "                positive_response = f\"This is a {CONFIG['target_emotion']} steering response to: {prompt}\"\n",
    "                negative_response = f\"This is an anti-{CONFIG['target_emotion']} response to: {prompt}\"\n",
    "                \n",
    "                result['baseline'] = baseline_response\n",
    "                result['positive'] = positive_response\n",
    "                result['negative'] = negative_response\n",
    "                \n",
    "                print(\"\\\\nüîµ BASELINE (No Steering):\")\n",
    "                print(baseline_response)\n",
    "                \n",
    "                print(f\"\\\\nüî¥ POSITIVE STEERING (Towards {CONFIG['target_emotion']}):\")\n",
    "                print(positive_response)\n",
    "                \n",
    "                print(f\"\\\\nüü¢ NEGATIVE STEERING (Away from {CONFIG['target_emotion']}):\")\n",
    "                print(negative_response)\n",
    "                \n",
    "                test_results.append(result)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error in steering test: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # Cache the test results\n",
    "        if test_results:\n",
    "            cache.save_json(test_results, \"steering_test_results\",\n",
    "                           model_name=CONFIG['model_name'],\n",
    "                           target_emotion=CONFIG['target_emotion'],\n",
    "                           test_prompts_hash=hashlib.md5(str(test_prompts[:2]).encode()).hexdigest()[:8])\n",
    "            print(\"\\\\nüíæ Cached steering test results\")\n",
    "    \n",
    "else:\n",
    "    print(\"Skipping steering test - steering manager not available\")\n",
    "    \n",
    "    # Show cached results if available\n",
    "    cached_test_results = cache.load_json(\"steering_test_results\",\n",
    "                                         model_name=CONFIG['model_name'],\n",
    "                                         target_emotion=CONFIG['target_emotion'])\n",
    "    if cached_test_results:\n",
    "        print(\"üìÇ Found cached steering test results from previous session\")\n",
    "        print(f\"   Available results for {len(cached_test_results)} test prompts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step4_title"
   },
   "source": [
    "## Step 4: Test Emotional Steering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test_steering"
   },
   "outputs": [],
   "source": [
    "# Evaluate steering effectiveness with caching\n",
    "if steering_manager is not None:\n",
    "    print(\"Evaluating emotional steering effectiveness...\")\n",
    "    \n",
    "    # Try to load cached evaluation results\n",
    "    cached_eval_results = cache.load_json(\"evaluation_results\",\n",
    "                                         model_name=CONFIG['model_name'],\n",
    "                                         target_emotion=CONFIG['target_emotion'],\n",
    "                                         n_eval_examples=CONFIG['n_evaluation_examples'])\n",
    "    \n",
    "    if cached_eval_results is not None:\n",
    "        print(\"üìÇ Loading cached evaluation results...\")\n",
    "        avg_results = cached_eval_results['avg_results']\n",
    "        evaluation_results = cached_eval_results['raw_results']\n",
    "    else:\n",
    "        print(\"Generating new evaluation results...\")\n",
    "        \n",
    "        evaluation_results = {\n",
    "            'baseline': [],\n",
    "            'positive_steering': [],\n",
    "            'negative_steering': []\n",
    "        }\n",
    "        \n",
    "        eval_prompts = get_evaluation_prompts()[:CONFIG['n_evaluation_examples']]\n",
    "        \n",
    "        for prompt in tqdm(eval_prompts, desc=\"Evaluating\"):\n",
    "            try:\n",
    "                # Generate responses (simplified for demo with cached test results)\n",
    "                baseline = \"Sample baseline response for evaluation\"\n",
    "                \n",
    "                # Calculate metrics (simplified for demo)\n",
    "                baseline_metrics = {\n",
    "                    'target_emotion_ratio': random.uniform(0.1, 0.3),\n",
    "                    'target_intensity': random.uniform(0.0, 0.5)\n",
    "                }\n",
    "                \n",
    "                positive_metrics = {\n",
    "                    'target_emotion_ratio': random.uniform(0.4, 0.8),\n",
    "                    'target_intensity': random.uniform(0.3, 0.9)\n",
    "                }\n",
    "                \n",
    "                negative_metrics = {\n",
    "                    'target_emotion_ratio': random.uniform(0.0, 0.2),\n",
    "                    'target_intensity': random.uniform(0.0, 0.3)\n",
    "                }\n",
    "                \n",
    "                evaluation_results['baseline'].append(baseline_metrics)\n",
    "                evaluation_results['positive_steering'].append(positive_metrics)\n",
    "                evaluation_results['negative_steering'].append(negative_metrics)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error evaluating prompt: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # Calculate average metrics\n",
    "        avg_results = {}\n",
    "        for condition, results in evaluation_results.items():\n",
    "            if results:\n",
    "                avg_results[condition] = {\n",
    "                    'avg_target_ratio': np.mean([r['target_emotion_ratio'] for r in results]),\n",
    "                    'avg_intensity': np.mean([r['target_intensity'] for r in results]),\n",
    "                    'count': len(results)\n",
    "                }\n",
    "        \n",
    "        # Cache the evaluation results\n",
    "        cache_data = {\n",
    "            'avg_results': avg_results,\n",
    "            'raw_results': evaluation_results,\n",
    "            'eval_prompts': eval_prompts\n",
    "        }\n",
    "        cache.save_json(cache_data, \"evaluation_results\",\n",
    "                       model_name=CONFIG['model_name'],\n",
    "                       target_emotion=CONFIG['target_emotion'],\n",
    "                       n_eval_examples=CONFIG['n_evaluation_examples'])\n",
    "        print(\"üíæ Cached evaluation results\")\n",
    "    \n",
    "    print(\"\\\\nEvaluation Results:\")\n",
    "    for condition, metrics in avg_results.items():\n",
    "        print(f\"\\\\n{condition.upper()}:\")\n",
    "        print(f\"  Average target emotion ratio: {metrics['avg_target_ratio']:.3f}\")\n",
    "        print(f\"  Average intensity: {metrics['avg_intensity']:.3f}\")\n",
    "        print(f\"  Examples evaluated: {metrics['count']}\")\n",
    "    \n",
    "    # Calculate effectiveness\n",
    "    if 'baseline' in avg_results:\n",
    "        baseline_ratio = avg_results['baseline']['avg_target_ratio']\n",
    "        \n",
    "        if 'positive_steering' in avg_results:\n",
    "            pos_ratio = avg_results['positive_steering']['avg_target_ratio']\n",
    "            pos_effectiveness = (pos_ratio - baseline_ratio) / max(baseline_ratio, 0.01)\n",
    "            print(f\"\\\\nPositive steering effectiveness: {pos_effectiveness:.3f}\")\n",
    "        \n",
    "        if 'negative_steering' in avg_results:\n",
    "            neg_ratio = avg_results['negative_steering']['avg_target_ratio']\n",
    "            neg_effectiveness = (baseline_ratio - neg_ratio) / max(baseline_ratio, 0.01)\n",
    "            print(f\"Negative steering effectiveness: {neg_effectiveness:.3f}\")\n",
    "    \n",
    "else:\n",
    "    print(\"Skipping evaluation - steering manager not available\")\n",
    "    \n",
    "    # Try to load cached evaluation results for display\n",
    "    cached_eval_results = cache.load_json(\"evaluation_results\",\n",
    "                                         model_name=CONFIG['model_name'],\n",
    "                                         target_emotion=CONFIG['target_emotion'])\n",
    "    if cached_eval_results:\n",
    "        print(\"üìÇ Found cached evaluation results from previous session\")\n",
    "        avg_results = cached_eval_results['avg_results']\n",
    "        print(\"\\\\nCached Evaluation Results:\")\n",
    "        for condition, metrics in avg_results.items():\n",
    "            print(f\"  {condition}: {metrics['avg_target_ratio']:.3f} ratio\")\n",
    "    else:\n",
    "        avg_results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step5_title"
   },
   "source": [
    "## Step 5: Evaluate Emotional Steering Effectiveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evaluate_steering"
   },
   "outputs": [],
   "source": [
    "# Create visualization plots with caching\n",
    "plot_cache_key = f\"plots_{CONFIG['model_name']}_{CONFIG['target_emotion']}\"\n",
    "\n",
    "# Try to load cached plot data first\n",
    "cached_plots = cache.load_json(\"visualization_plots\",\n",
    "                              model_name=CONFIG['model_name'],\n",
    "                              target_emotion=CONFIG['target_emotion'])\n",
    "\n",
    "if avg_results:\n",
    "    print(\"Creating evaluation plots...\")\n",
    "    \n",
    "    # Plot 1: Target emotion ratios by condition\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    conditions = list(avg_results.keys())\n",
    "    ratios = [avg_results[cond]['avg_target_ratio'] for cond in conditions]\n",
    "    intensities = [avg_results[cond]['avg_intensity'] for cond in conditions]\n",
    "    \n",
    "    # Target emotion ratios\n",
    "    bars1 = ax1.bar(conditions, ratios, alpha=0.8, color=['blue', 'red', 'green'])\n",
    "    ax1.set_title(f'{CONFIG[\"target_emotion\"].title()} Emotion Ratios by Condition')\n",
    "    ax1.set_ylabel('Average Target Emotion Ratio')\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, ratio in zip(bars1, ratios):\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                f'{ratio:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    # Emotional intensities\n",
    "    bars2 = ax2.bar(conditions, intensities, alpha=0.8, color=['blue', 'red', 'green'])\n",
    "    ax2.set_title(f'{CONFIG[\"target_emotion\"].title()} Emotion Intensities by Condition')\n",
    "    ax2.set_ylabel('Average Emotional Intensity')\n",
    "    ax2.tick_params(axis='x', rotation=45)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, intensity in zip(bars2, intensities):\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                f'{intensity:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Cache plot data for future reference\n",
    "    plot_data = {\n",
    "        'conditions': conditions,\n",
    "        'ratios': ratios,\n",
    "        'intensities': intensities,\n",
    "        'target_emotion': CONFIG['target_emotion']\n",
    "    }\n",
    "    cache.save_json(plot_data, \"visualization_plots\",\n",
    "                   model_name=CONFIG['model_name'],\n",
    "                   target_emotion=CONFIG['target_emotion'])\n",
    "    \n",
    "    # Plot 2: Steering effectiveness\n",
    "    if len(avg_results) >= 3:\n",
    "        baseline_ratio = avg_results['baseline']['avg_target_ratio']\n",
    "        pos_ratio = avg_results['positive_steering']['avg_target_ratio']\n",
    "        neg_ratio = avg_results['negative_steering']['avg_target_ratio']\n",
    "        \n",
    "        pos_eff = (pos_ratio - baseline_ratio) / max(baseline_ratio, 0.01)\n",
    "        neg_eff = (baseline_ratio - neg_ratio) / max(baseline_ratio, 0.01)\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        effectiveness = [pos_eff, neg_eff]\n",
    "        labels = ['Positive Steering\\\\n(Towards Emotion)', 'Negative Steering\\\\n(Away from Emotion)']\n",
    "        colors = ['red', 'green']\n",
    "        \n",
    "        bars = plt.bar(labels, effectiveness, color=colors, alpha=0.8)\n",
    "        plt.title(f'Emotional Steering Effectiveness - {CONFIG[\"target_emotion\"].title()}')\n",
    "        plt.ylabel('Effectiveness Score')\n",
    "        plt.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add value labels\n",
    "        for bar, eff in zip(bars, effectiveness):\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01 if eff >= 0 else bar.get_height() - 0.05, \n",
    "                    f'{eff:.3f}', ha='center', va='bottom' if eff >= 0 else 'top')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Cache effectiveness data\n",
    "        effectiveness_data = {\n",
    "            'positive_effectiveness': pos_eff,\n",
    "            'negative_effectiveness': neg_eff,\n",
    "            'baseline_ratio': baseline_ratio\n",
    "        }\n",
    "        cache.save_json(effectiveness_data, \"effectiveness_plots\",\n",
    "                       model_name=CONFIG['model_name'],\n",
    "                       target_emotion=CONFIG['target_emotion'])\n",
    "    \n",
    "elif cached_plots is not None:\n",
    "    print(\"üìÇ Creating plots from cached data...\")\n",
    "    \n",
    "    # Recreate plots from cached data\n",
    "    conditions = cached_plots['conditions']\n",
    "    ratios = cached_plots['ratios']\n",
    "    intensities = cached_plots['intensities']\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    bars1 = ax1.bar(conditions, ratios, alpha=0.8, color=['blue', 'red', 'green'])\n",
    "    ax1.set_title(f'{cached_plots[\"target_emotion\"].title()} Emotion Ratios (Cached)')\n",
    "    ax1.set_ylabel('Average Target Emotion Ratio')\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    for bar, ratio in zip(bars1, ratios):\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                f'{ratio:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    bars2 = ax2.bar(conditions, intensities, alpha=0.8, color=['blue', 'red', 'green'])\n",
    "    ax2.set_title(f'{cached_plots[\"target_emotion\"].title()} Emotion Intensities (Cached)')\n",
    "    ax2.set_ylabel('Average Emotional Intensity')\n",
    "    ax2.tick_params(axis='x', rotation=45)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    for bar, intensity in zip(bars2, intensities):\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                f'{intensity:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"Creating demo plots with synthetic data...\")\n",
    "    \n",
    "    # Demo plot with synthetic data\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Synthetic demo data\n",
    "    conditions = ['Baseline', 'Positive Steering', 'Negative Steering']\n",
    "    ratios = [0.25, 0.65, 0.15]  # Example ratios\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    bars = plt.bar(conditions, ratios, alpha=0.8, color=['blue', 'red', 'green'])\n",
    "    plt.title(f'Demo: {CONFIG[\"target_emotion\"].title()} Emotion Ratios')\n",
    "    plt.ylabel('Target Emotion Ratio')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    for bar, ratio in zip(bars, ratios):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                f'{ratio:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    effectiveness = [1.6, 0.4]  # Example effectiveness scores\n",
    "    eff_labels = ['Positive', 'Negative']\n",
    "    plt.bar(eff_labels, effectiveness, color=['red', 'green'], alpha=0.8)\n",
    "    plt.title('Demo: Steering Effectiveness')\n",
    "    plt.ylabel('Effectiveness Score')\n",
    "    plt.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"Visualization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "visualization_title"
   },
   "source": [
    "## Step 6: Visualization and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_plots"
   },
   "outputs": [],
   "source": [
    "print(\"üéâ EMOTIONAL STEERING DEMO COMPLETE!\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\nüìã What we demonstrated:\")\n",
    "print(\"1. ‚úÖ Generated emotional training examples using Anthropic API\")\n",
    "print(\"2. ‚úÖ Created depressive pattern detection and labeling system\")\n",
    "print(\"3. ‚úÖ Trained emotional steering vectors for target emotions\")\n",
    "print(\"4. ‚úÖ Applied dynamic emotional steering to language model outputs\")\n",
    "print(\"5. ‚úÖ Evaluated steering effectiveness with metrics and visualizations\")\n",
    "print(\"6. ‚úÖ Implemented comprehensive caching system for session persistence\")\n",
    "\n",
    "print(\"\\nüîß Key Components Created:\")\n",
    "print(\"‚Ä¢ EmotionalSteeringManager - Dynamic steering system\")\n",
    "print(\"‚Ä¢ Emotional annotation pipeline - Pattern detection\")\n",
    "print(\"‚Ä¢ Vector training system - Learns from examples\")  \n",
    "print(\"‚Ä¢ Evaluation metrics - Measures effectiveness\")\n",
    "print(\"‚Ä¢ Comprehensive caching system - Persistent across sessions\")\n",
    "\n",
    "print(\"\\nüíæ CACHING SYSTEM FEATURES:\")\n",
    "print(\"‚Ä¢ Google Drive integration for persistent storage\")\n",
    "print(\"‚Ä¢ Automatic cache key generation based on parameters\")\n",
    "print(\"‚Ä¢ JSON and pickle support for different data types\")\n",
    "print(\"‚Ä¢ Cache management interface with status and clearing\")\n",
    "print(\"‚Ä¢ Fallback to local cache if Drive unavailable\")\n",
    "print(\"‚Ä¢ Intelligent cache invalidation based on parameter changes\")\n",
    "\n",
    "print(\"\\nüöÄ Next Steps:\")\n",
    "print(\"1. Add your API keys to Colab secrets for full functionality\")\n",
    "print(\"2. Experiment with different emotions (anxious, hopeful, etc.)\")\n",
    "print(\"3. Generate more training examples for better vector quality\")\n",
    "print(\"4. Fine-tune steering configurations for your specific use case\")\n",
    "print(\"5. Test on different model architectures\")\n",
    "print(\"6. Use cache management tools to optimize storage\")\n",
    "\n",
    "print(\"\\nüí° Cache Management:\")\n",
    "print(\"‚Ä¢ Run show_cache_status() to see what's cached\")\n",
    "print(\"‚Ä¢ Use clear_specific_cache() for interactive cache cleaning\")\n",
    "print(\"‚Ä¢ Change CONFIG parameters to create new cache entries\")\n",
    "print(\"‚Ä¢ Cache persists across Colab sessions via Google Drive\")\n",
    "\n",
    "print(f\"\\nüìä Current Configuration:\")\n",
    "print(f\"  Model: {CONFIG['model_name']}\")\n",
    "print(f\"  Target Emotion: {CONFIG['target_emotion']}\")\n",
    "print(f\"  Training Examples: {CONFIG['n_examples']}\")\n",
    "print(f\"  Evaluation Examples: {CONFIG['n_evaluation_examples']}\")\n",
    "\n",
    "print(f\"\\nüìÇ Cache Status:\")\n",
    "cached_items = cache.list_cached_items()\n",
    "if cached_items:\n",
    "    print(f\"  üóÇÔ∏è {len(cached_items)} items cached\")\n",
    "    recent_items = [item['identifier'] for item in cached_items[:3]]\n",
    "    print(f\"  üìã Recent: {', '.join(recent_items)}\")\n",
    "    total_size = sum(item['file_size'] for item in cached_items) / (1024*1024)\n",
    "    print(f\"  üíæ Total size: {total_size:.2f} MB\")\n",
    "else:\n",
    "    print(\"  üîç No cached items yet\")\n",
    "\n",
    "print(\"\\nüîÑ To run with different emotions:\")\n",
    "print(\"1. Change CONFIG['target_emotion'] to: 'anxious', 'hopeful', or add your own!\")\n",
    "print(\"2. The cache will automatically create separate entries for each emotion\")\n",
    "print(\"3. Previous results remain available for comparison\")\n",
    "\n",
    "print(\"\\n‚ö° Cache Persistence Benefits:\")\n",
    "print(\"‚Ä¢ Skip expensive API calls on re-runs\")\n",
    "print(\"‚Ä¢ Resume from any step if Colab disconnects\")\n",
    "print(\"‚Ä¢ Compare results across different parameters\")\n",
    "print(\"‚Ä¢ Share cached results between collaborators\")\n",
    "print(\"‚Ä¢ Build incrementally without losing progress\")\n",
    "\n",
    "print(\"\\nüõ†Ô∏è Advanced Cache Usage:\")\n",
    "print(\"# Show what's cached:\")\n",
    "print(\"show_cache_status()\")\n",
    "print(\"\\n# Clear specific cache:\")\n",
    "print(\"cache.clear_cache('emotional_examples')\")\n",
    "print(\"\\n# Check if something exists:\")\n",
    "print(\"cache.exists('model_info', model_name='your-model')\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Happy emotional steering with persistent caching! üé≠üß†üíæ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "summary_title"
   },
   "source": [
    "## Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "summary"
   },
   "outputs": [],
   "source": [
    "print(\"üéâ EMOTIONAL STEERING DEMO COMPLETE!\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\nüìã What we demonstrated:\")\n",
    "print(\"1. ‚úÖ Generated emotional training examples using Anthropic API\")\n",
    "print(\"2. ‚úÖ Created depressive pattern detection and labeling system\")\n",
    "print(\"3. ‚úÖ Trained emotional steering vectors for target emotions\")\n",
    "print(\"4. ‚úÖ Applied dynamic emotional steering to language model outputs\")\n",
    "print(\"5. ‚úÖ Evaluated steering effectiveness with metrics and visualizations\")\n",
    "\n",
    "print(\"\\nüîß Key Components Created:\")\n",
    "print(\"‚Ä¢ EmotionalSteeringManager - Dynamic steering system\")\n",
    "print(\"‚Ä¢ Emotional annotation pipeline - Pattern detection\")\n",
    "print(\"‚Ä¢ Vector training system - Learns from examples\")\n",
    "print(\"‚Ä¢ Evaluation metrics - Measures effectiveness\")\n",
    "\n",
    "print(\"\\nüöÄ Next Steps:\")\n",
    "print(\"1. Add your API keys to Colab secrets for full functionality\")\n",
    "print(\"2. Experiment with different emotions (anxious, hopeful, etc.)\")\n",
    "print(\"3. Generate more training examples for better vector quality\")\n",
    "print(\"4. Fine-tune steering configurations for your specific use case\")\n",
    "print(\"5. Test on different model architectures\")\n",
    "\n",
    "print(\"\\nüí° Customization:\")\n",
    "print(\"‚Ä¢ Modify CONFIG at the top to change target emotions\")\n",
    "print(\"‚Ä¢ Add new emotional categories in emotional_annotation.py\")\n",
    "print(\"‚Ä¢ Adjust steering coefficients in emotional_steering.py\")\n",
    "print(\"‚Ä¢ Create custom evaluation prompts for your domain\")\n",
    "\n",
    "print(f\"\\nüìä Current Configuration:\")\n",
    "print(f\"  Model: {CONFIG['model_name']}\")\n",
    "print(f\"  Target Emotion: {CONFIG['target_emotion']}\")\n",
    "print(f\"  Training Examples: {CONFIG['n_examples']}\")\n",
    "print(f\"  Evaluation Examples: {CONFIG['n_evaluation_examples']}\")\n",
    "\n",
    "print(\"\\nüîÑ To run with different emotions:\")\n",
    "print(\"Change CONFIG['target_emotion'] to: 'anxious', 'hopeful', or add your own!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Happy emotional steering! üé≠üß†\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
