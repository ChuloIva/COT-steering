{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotional Reasoning Steering with COT-Steering Framework\n",
    "\n",
    "This notebook provides a comprehensive implementation of emotional reasoning steering for language models, extending the existing COT-steering framework to include depressive and anxious thinking patterns.\n",
    "\n",
    "## Overview\n",
    "\n",
    "This implementation allows you to:\n",
    "1. **Train steering vectors** for emotional reasoning patterns (depressive, anxious, negative attribution, pessimistic projection)\n",
    "2. **Steer models** toward or away from these emotional patterns during generation\n",
    "3. **Evaluate the effectiveness** of emotional steering\n",
    "4. **Analyze emotional content** in model outputs\n",
    "\n",
    "## ‚ö†Ô∏è Important Safety Notice\n",
    "\n",
    "This implementation is intended for **research purposes only**. Steering models toward negative emotional states could be harmful if misused. Please:\n",
    "- Use only for legitimate research with proper ethical oversight\n",
    "- Always provide counterbalancing positive steering capabilities\n",
    "- Never deploy this in production systems without appropriate safeguards\n",
    "- Ensure users are aware when emotional steering is active\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if not already installed\n",
    "# !pip install torch transformers nnsight openai anthropic python-dotenv tqdm matplotlib seaborn pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dependencies loaded successfully!\n",
      "üêç Python version: 3.10.18 (main, Jun  3 2025, 18:23:41) [Clang 17.0.0 (clang-1700.0.13.3)]\n",
      "üî• PyTorch version: 2.5.1\n",
      "üíæ CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add paths to import local modules\n",
    "sys.path.append('./utils')\n",
    "sys.path.append('./messages')\n",
    "\n",
    "# Import required libraries\n",
    "import torch\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import our custom modules\n",
    "from utils import (\n",
    "    load_model_and_vectors, \n",
    "    process_batch_annotations,\n",
    "    process_saved_responses_batch,\n",
    "    custom_generate_steering,\n",
    "    analyze_emotional_content,\n",
    "    generate_and_analyze_emotional,\n",
    "    steering_config,\n",
    "    chat\n",
    ")\n",
    "\n",
    "from messages import messages, eval_messages\n",
    "\n",
    "print(\"‚úÖ Dependencies loaded successfully!\")\n",
    "print(f\"üêç Python version: {sys.version}\")\n",
    "print(f\"üî• PyTorch version: {torch.__version__}\")\n",
    "print(f\"üíæ CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Configuration:\n",
      "   model_name: deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\n",
      "   device: auto\n",
      "   load_in_8bit: False\n",
      "   max_new_tokens: 1000\n",
      "   batch_size: 4\n",
      "   include_emotional: True\n",
      "   results_dir: ./results\n",
      "   timestamp: 20250726_200502\n"
     ]
    }
   ],
   "source": [
    "# Configuration settings\n",
    "CONFIG = {\n",
    "    \"model_name\": \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",  # Change as needed\n",
    "    \"device\": \"auto\",  # auto-detect, or specify \"cuda\", \"mps\", \"cpu\"\n",
    "    \"load_in_8bit\": False,\n",
    "    \"max_new_tokens\": 1000,\n",
    "    \"batch_size\": 4,\n",
    "    \"include_emotional\": True,  # Whether to include emotional reasoning in training\n",
    "    \"results_dir\": \"./results\",\n",
    "    \"timestamp\": datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "}\n",
    "\n",
    "# Create results directory\n",
    "os.makedirs(CONFIG[\"results_dir\"], exist_ok=True)\n",
    "os.makedirs(f\"{CONFIG['results_dir']}/figures\", exist_ok=True)\n",
    "os.makedirs(f\"{CONFIG['results_dir']}/data\", exist_ok=True)\n",
    "\n",
    "print(f\"üìã Configuration:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"   {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Model and Existing Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06f4f45454a54342af8edfc80ea23f25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# Log in to Hugging Face Hub using API key (set HUGGINGFACE_TOKEN env variable or paste when prompted)\n",
    "login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Loading model and tokenizer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1aede2ad4704df09892e0280c92b226",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.55G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"ü§ñ Loading model and tokenizer...\")\n",
    "\n",
    "model, tokenizer, existing_vectors = load_model_and_vectors(\n",
    "    device=CONFIG[\"device\"],\n",
    "    load_in_8bit=CONFIG[\"load_in_8bit\"],\n",
    "    compute_features=True,\n",
    "    model_name=CONFIG[\"model_name\"]\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Model loaded: {CONFIG['model_name']}\")\n",
    "print(f\"üìä Device: {next(model.parameters()).device}\")\n",
    "print(f\"üéØ Model has {model.config.num_hidden_layers} layers\")\n",
    "print(f\"üìù Vocabulary size: {len(tokenizer)}\")\n",
    "\n",
    "if existing_vectors:\n",
    "    print(f\"üì¶ Existing feature vectors found: {list(existing_vectors.keys())}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No existing feature vectors found - will need to train from scratch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unrecognized keys in `rope_scaling` for 'rope_type'='yarn': {'attn_factor'}\n",
      "Unrecognized keys in `rope_scaling` for 'rope_type'='yarn': {'attn_factor'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddde24e8abfa42e19ba4e8e4a35f0855",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46444249947a4c5b9f071f7a4ac618e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "872c7abbaa114a27807ed837d95224b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-000002.safetensors:   0%|          | 0.00/8.61G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d04ba2cc24ef47ceb3738e0d6c8b5b80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-000002.safetensors:   0%|          | 0.00/7.77G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cancellation requested; stopping current tasks.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Set your token as environment variable or directly\u001b[39;00m\n\u001b[1;32m      5\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHF_TOKEN\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhf_hloWDvluGLJjaRebJSbIZPTcLmkCNMGPNr\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 7\u001b[0m pipe \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext-generation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdeepseek-ai/DeepSeek-R1-0528-Qwen3-8B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# This will use your HF token\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Projects/thinking_model_proj/COT-steering/COT-steering/.venv/lib/python3.10/site-packages/transformers/pipelines/__init__.py:1008\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1007\u001b[0m     model_classes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n\u001b[0;32m-> 1008\u001b[0m     framework, model \u001b[38;5;241m=\u001b[39m \u001b[43minfer_framework_load_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m        \u001b[49m\u001b[43madapter_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43madapter_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[43m        \u001b[49m\u001b[43mframework\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframework\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1018\u001b[0m hub_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39m_commit_hash\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;66;03m# Check which preprocessing classes the pipeline uses\u001b[39;00m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;66;03m# None values indicate optional classes that the pipeline can run without, we don't raise errors if loading fails\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Projects/thinking_model_proj/COT-steering/COT-steering/.venv/lib/python3.10/site-packages/transformers/pipelines/base.py:292\u001b[0m, in \u001b[0;36minfer_framework_load_model\u001b[0;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[1;32m    286\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    287\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel might be a PyTorch model (ending with `.bin`) but PyTorch is not available. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    288\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrying to load the model with Tensorflow.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    289\u001b[0m     )\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 292\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    294\u001b[0m         model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/Desktop/Projects/thinking_model_proj/COT-steering/COT-steering/.venv/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:600\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mconfig_class \u001b[38;5;241m==\u001b[39m config\u001b[38;5;241m.\u001b[39msub_configs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    599\u001b[0m         config \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget_text_config()\n\u001b[0;32m--> 600\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    604\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    605\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    606\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/Projects/thinking_model_proj/COT-steering/COT-steering/.venv/lib/python3.10/site-packages/transformers/modeling_utils.py:315\u001b[0m, in \u001b[0;36mrestore_default_torch_dtype.<locals>._wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    313\u001b[0m old_dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mget_default_dtype()\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    317\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_default_dtype(old_dtype)\n",
      "File \u001b[0;32m~/Desktop/Projects/thinking_model_proj/COT-steering/COT-steering/.venv/lib/python3.10/site-packages/transformers/modeling_utils.py:4851\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4841\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   4842\u001b[0m     gguf_file\n\u001b[1;32m   4843\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m device_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   4844\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m ((\u001b[38;5;28misinstance\u001b[39m(device_map, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisk\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisk\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map)\n\u001b[1;32m   4845\u001b[0m ):\n\u001b[1;32m   4846\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   4847\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOne or more modules is configured to be mapped to disk. Disk offload is not supported for models \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4848\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloaded from GGUF files.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4849\u001b[0m     )\n\u001b[0;32m-> 4851\u001b[0m checkpoint_files, sharded_metadata \u001b[38;5;241m=\u001b[39m \u001b[43m_get_resolved_checkpoint_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4852\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4853\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4854\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvariant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4855\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgguf_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgguf_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4856\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_tf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_flax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4858\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_safetensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4859\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4860\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4861\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4863\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4864\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4865\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4866\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4867\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_auto_class\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   4868\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransformers_explicit_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransformers_explicit_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4869\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4871\u001b[0m is_sharded \u001b[38;5;241m=\u001b[39m sharded_metadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   4872\u001b[0m is_quantized \u001b[38;5;241m=\u001b[39m hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Projects/thinking_model_proj/COT-steering/COT-steering/.venv/lib/python3.10/site-packages/transformers/modeling_utils.py:1299\u001b[0m, in \u001b[0;36m_get_resolved_checkpoint_files\u001b[0;34m(pretrained_model_name_or_path, subfolder, variant, gguf_file, from_tf, from_flax, use_safetensors, cache_dir, force_download, proxies, local_files_only, token, user_agent, revision, commit_hash, is_remote_code, transformers_explicit_filename)\u001b[0m\n\u001b[1;32m   1297\u001b[0m sharded_metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_sharded:\n\u001b[0;32m-> 1299\u001b[0m     checkpoint_files, sharded_metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_checkpoint_shard_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1301\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1302\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1303\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1306\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1307\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1309\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1310\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1311\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1312\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1313\u001b[0m     checkpoint_files \u001b[38;5;241m=\u001b[39m [resolved_archive_file] \u001b[38;5;28;01mif\u001b[39;00m pretrained_model_name_or_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Projects/thinking_model_proj/COT-steering/COT-steering/.venv/lib/python3.10/site-packages/transformers/utils/hub.py:1117\u001b[0m, in \u001b[0;36mget_checkpoint_shard_files\u001b[0;34m(pretrained_model_name_or_path, index_filename, cache_dir, force_download, proxies, resume_download, local_files_only, token, user_agent, revision, subfolder, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m shard_filenames, sharded_metadata\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;66;03m# At this stage pretrained_model_name_or_path is a model identifier on the Hub. Try to get everything from cache,\u001b[39;00m\n\u001b[1;32m   1116\u001b[0m \u001b[38;5;66;03m# or download the files\u001b[39;00m\n\u001b[0;32m-> 1117\u001b[0m cached_filenames \u001b[38;5;241m=\u001b[39m \u001b[43mcached_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1119\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshard_filenames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1126\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1128\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1129\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_commit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1130\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cached_filenames, sharded_metadata\n",
      "File \u001b[0;32m~/Desktop/Projects/thinking_model_proj/COT-steering/COT-steering/.venv/lib/python3.10/site-packages/transformers/utils/hub.py:491\u001b[0m, in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m         hf_hub_download(\n\u001b[1;32m    477\u001b[0m             path_or_repo_id,\n\u001b[1;32m    478\u001b[0m             filenames[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    488\u001b[0m             local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m    489\u001b[0m         )\n\u001b[1;32m    490\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 491\u001b[0m         \u001b[43msnapshot_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_patterns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_filenames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m            \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m            \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;66;03m# We cannot recover from them\u001b[39;00m\n\u001b[1;32m    507\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, RepositoryNotFoundError) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, GatedRepoError):\n",
      "File \u001b[0;32m~/Desktop/Projects/thinking_model_proj/COT-steering/COT-steering/.venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Projects/thinking_model_proj/COT-steering/COT-steering/.venv/lib/python3.10/site-packages/huggingface_hub/_snapshot_download.py:332\u001b[0m, in \u001b[0;36msnapshot_download\u001b[0;34m(repo_id, repo_type, revision, cache_dir, local_dir, library_name, library_version, user_agent, proxies, etag_timeout, force_download, token, local_files_only, allow_patterns, ignore_patterns, max_workers, tqdm_class, headers, endpoint, local_dir_use_symlinks, resume_download)\u001b[0m\n\u001b[1;32m    330\u001b[0m         _inner_hf_hub_download(file)\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 332\u001b[0m     \u001b[43mthread_map\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_inner_hf_hub_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfiltered_repo_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtqdm_desc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# User can use its own tqdm class or the default one from `huggingface_hub.utils`\u001b[39;49;00m\n\u001b[1;32m    338\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtqdm_class\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhf_tqdm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m local_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mrealpath(local_dir))\n",
      "File \u001b[0;32m~/Desktop/Projects/thinking_model_proj/COT-steering/COT-steering/.venv/lib/python3.10/site-packages/tqdm/contrib/concurrent.py:69\u001b[0m, in \u001b[0;36mthread_map\u001b[0;34m(fn, *iterables, **tqdm_kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03mEquivalent of `list(map(fn, *iterables))`\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;124;03mdriven by `concurrent.futures.ThreadPoolExecutor`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03m    [default: max(32, cpu_count() + 4)].\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mconcurrent\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfutures\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ThreadPoolExecutor\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_executor_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mThreadPoolExecutor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43miterables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtqdm_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Projects/thinking_model_proj/COT-steering/COT-steering/.venv/lib/python3.10/site-packages/tqdm/contrib/concurrent.py:51\u001b[0m, in \u001b[0;36m_executor_map\u001b[0;34m(PoolExecutor, fn, *iterables, **tqdm_kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ensure_lock(tqdm_class, lock_name\u001b[38;5;241m=\u001b[39mlock_name) \u001b[38;5;28;01mas\u001b[39;00m lk:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;66;03m# share lock in case workers are already using `tqdm`\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m PoolExecutor(max_workers\u001b[38;5;241m=\u001b[39mmax_workers, initializer\u001b[38;5;241m=\u001b[39mtqdm_class\u001b[38;5;241m.\u001b[39mset_lock,\n\u001b[1;32m     50\u001b[0m                       initargs\u001b[38;5;241m=\u001b[39m(lk,)) \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[0;32m---> 51\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43miterables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Projects/thinking_model_proj/COT-steering/COT-steering/.venv/lib/python3.10/site-packages/tqdm/notebook.py:250\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    249\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[0;32m--> 250\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[1;32m    251\u001b[0m         \u001b[38;5;66;03m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Projects/thinking_model_proj/COT-steering/COT-steering/.venv/lib/python3.10/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.18/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/_base.py:621\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[1;32m    619\u001b[0m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 621\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_result_or_cancel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    623\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs\u001b[38;5;241m.\u001b[39mpop(), end_time \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic())\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.18/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/_base.py:319\u001b[0m, in \u001b[0;36m_result_or_cancel\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 319\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    321\u001b[0m         fut\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.18/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.18/Frameworks/Python.framework/Versions/3.10/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import os\n",
    "\n",
    "# Set your token as environment variable or directly\n",
    "os.environ[\"HF_TOKEN\"] = \"\"\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\", \n",
    "    model=\"deepseek-ai/DeepSeek-R1-0528-Qwen3-8B\",\n",
    "    token=True  # This will use your HF token\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Prepare Emotional Reasoning Messages\n",
    "\n",
    "We'll select messages specifically designed to elicit emotional reasoning patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter messages for emotional reasoning\n",
    "emotional_messages = []\n",
    "cognitive_messages = []\n",
    "\n",
    "for msg in messages:\n",
    "    content = msg[\"content\"]\n",
    "    # Simple heuristic to identify emotional vs cognitive messages\n",
    "    emotional_indicators = [\n",
    "        \"you've been\", \"your recent\", \"everyone around you\", \"after receiving\",\n",
    "        \"what does this\", \"how do you interpret\", \"what might this\", \"what are all the ways\",\n",
    "        \"walk through all\", \"consider all the potential\", \"what could this\",\n",
    "        \"what are the various\", \"what are the ways\", \"what challenges\", \"what obstacles\"\n",
    "    ]\n",
    "    \n",
    "    if any(indicator in content.lower() for indicator in emotional_indicators):\n",
    "        emotional_messages.append(msg)\n",
    "    else:\n",
    "        cognitive_messages.append(msg)\n",
    "\n",
    "print(f\"üìä Message breakdown:\")\n",
    "print(f\"   üß† Cognitive messages: {len(cognitive_messages)}\")\n",
    "print(f\"   üòî Emotional messages: {len(emotional_messages)}\")\n",
    "print(f\"   üìù Total messages: {len(messages)}\")\n",
    "\n",
    "# Show examples of emotional messages\n",
    "print(f\"\\nüìù Example emotional messages:\")\n",
    "for i, msg in enumerate(emotional_messages[:3]):\n",
    "    print(f\"   {i+1}. {msg['content'][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Generate Responses for Training Data\n",
    "\n",
    "Generate responses to emotional reasoning prompts to create training data for steering vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_responses_batch(model, tokenizer, messages_subset, max_new_tokens=1000):\n",
    "    \"\"\"Generate responses for a batch of messages\"\"\"\n",
    "    responses = []\n",
    "    \n",
    "    for msg in tqdm(messages_subset, desc=\"Generating responses\"):\n",
    "        try:\n",
    "            # Tokenize the message\n",
    "            input_ids = tokenizer.encode(msg[\"content\"], return_tensors=\"pt\")\n",
    "            \n",
    "            # Generate response without steering (baseline)\n",
    "            with model.generate(\n",
    "                {\"input_ids\": input_ids, \"attention_mask\": (input_ids != tokenizer.pad_token_id).long()},\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                pad_token_id=tokenizer.pad_token_id\n",
    "            ) as tracer:\n",
    "                output = model.generator.output.save()\n",
    "            \n",
    "            # Decode the response\n",
    "            response_text = tokenizer.decode(output.value[0], skip_special_tokens=True)\n",
    "            \n",
    "            # Remove input from response\n",
    "            input_text = tokenizer.decode(input_ids[0], skip_special_tokens=True)\n",
    "            if response_text.startswith(input_text):\n",
    "                response_text = response_text[len(input_text):].strip()\n",
    "            \n",
    "            responses.append({\n",
    "                \"message\": msg[\"content\"],\n",
    "                \"response\": response_text\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error generating response: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return responses\n",
    "\n",
    "# Generate responses for emotional messages (subset for training)\n",
    "print(\"üîÑ Generating responses for emotional reasoning training...\")\n",
    "training_messages = emotional_messages[:20]  # Use first 20 for training\n",
    "emotional_responses = generate_responses_batch(\n",
    "    model, tokenizer, training_messages, CONFIG[\"max_new_tokens\"]\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Generated {len(emotional_responses)} emotional responses\")\n",
    "\n",
    "# Show example response\n",
    "if emotional_responses:\n",
    "    print(f\"\\nüìù Example response:\")\n",
    "    print(f\"   Input: {emotional_responses[0]['message'][:100]}...\")\n",
    "    print(f\"   Output: {emotional_responses[0]['response'][:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Annotate Responses with Emotional Labels\n",
    "\n",
    "Use GPT-4 to annotate the responses with both cognitive and emotional reasoning labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üè∑Ô∏è  Annotating responses with emotional labels...\")\n",
    "\n",
    "# Extract just the response texts for annotation\n",
    "response_texts = [resp[\"response\"] for resp in emotional_responses]\n",
    "\n",
    "# Annotate with both cognitive and emotional labels\n",
    "annotated_responses = process_batch_annotations(\n",
    "    response_texts, include_emotional=True\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Annotated {len(annotated_responses)} responses\")\n",
    "\n",
    "# Show example annotation\n",
    "if annotated_responses:\n",
    "    print(f\"\\nüìù Example annotation:\")\n",
    "    print(f\"   Original: {response_texts[0][:150]}...\")\n",
    "    print(f\"   Annotated: {annotated_responses[0][:300]}...\")\n",
    "\n",
    "# Save annotated responses\n",
    "annotation_data = {\n",
    "    \"timestamp\": CONFIG[\"timestamp\"],\n",
    "    \"model_name\": CONFIG[\"model_name\"],\n",
    "    \"responses\": [\n",
    "        {\n",
    "            \"message\": emotional_responses[i][\"message\"],\n",
    "            \"response\": emotional_responses[i][\"response\"],\n",
    "            \"annotation\": annotated_responses[i]\n",
    "        }\n",
    "        for i in range(len(emotional_responses))\n",
    "    ]\n",
    "}\n",
    "\n",
    "with open(f\"{CONFIG['results_dir']}/data/emotional_annotations_{CONFIG['timestamp']}.json\", \"w\") as f:\n",
    "    json.dump(annotation_data, f, indent=2)\n",
    "\n",
    "print(f\"üíæ Saved annotations to {CONFIG['results_dir']}/data/emotional_annotations_{CONFIG['timestamp']}.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Extract Neural Activations and Train Emotional Vectors\n",
    "\n",
    "Process the annotated responses to extract neural activations for each emotional reasoning category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_label_positions\n",
    "\n",
    "def train_emotional_vectors(responses, annotations, model, tokenizer):\n",
    "    \"\"\"Train steering vectors for emotional reasoning categories\"\"\"\n",
    "    \n",
    "    # Get neural activations for all responses\n",
    "    print(\"üß† Extracting neural activations...\")\n",
    "    batch_activations = process_saved_responses_batch(responses, tokenizer, model)\n",
    "    \n",
    "    # Initialize storage for activations by label\n",
    "    label_activations = {\n",
    "        \"depressive-thinking\": [],\n",
    "        \"anxious-thinking\": [],\n",
    "        \"negative-attribution\": [],\n",
    "        \"pessimistic-projection\": [],\n",
    "        \"overall\": []\n",
    "    }\n",
    "    \n",
    "    print(\"üè∑Ô∏è  Processing annotations and extracting labeled activations...\")\n",
    "    \n",
    "    for i, (response, annotation) in enumerate(zip(responses, annotations)):\n",
    "        try:\n",
    "            # Get label positions in the response\n",
    "            label_positions = get_label_positions(annotation, response, tokenizer)\n",
    "            \n",
    "            # Get activations for this response\n",
    "            activations = batch_activations[i]  # Shape: (layers, seq_len, hidden_size)\n",
    "            \n",
    "            # Store all activations for overall mean\n",
    "            for layer_idx in range(activations.shape[0]):\n",
    "                for token_idx in range(activations.shape[1]):\n",
    "                    label_activations[\"overall\"].append(activations[layer_idx, token_idx])\n",
    "            \n",
    "            # Extract activations for each emotional label\n",
    "            for label, positions in label_positions.items():\n",
    "                if label in label_activations:\n",
    "                    for start_pos, end_pos in positions:\n",
    "                        # Extract activations for this labeled segment\n",
    "                        for layer_idx in range(activations.shape[0]):\n",
    "                            for token_idx in range(start_pos, min(end_pos, activations.shape[1])):\n",
    "                                label_activations[label].append(activations[layer_idx, token_idx])\n",
    "                                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing response {i}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Compute mean vectors for each label\n",
    "    print(\"üìä Computing mean vectors...\")\n",
    "    mean_vectors = {}\n",
    "    \n",
    "    for label, activations_list in label_activations.items():\n",
    "        if activations_list:\n",
    "            # Stack all activations and compute mean\n",
    "            activations_tensor = torch.stack(activations_list)\n",
    "            mean_vector = activations_tensor.mean(dim=0)\n",
    "            \n",
    "            mean_vectors[label] = {\n",
    "                'mean': mean_vector,\n",
    "                'count': len(activations_list)\n",
    "            }\n",
    "            \n",
    "            print(f\"   {label}: {len(activations_list)} activations\")\n",
    "        else:\n",
    "            print(f\"   {label}: No activations found\")\n",
    "    \n",
    "    return mean_vectors\n",
    "\n",
    "# Train emotional vectors\n",
    "print(\"üéØ Training emotional steering vectors...\")\n",
    "emotional_mean_vectors = train_emotional_vectors(\n",
    "    response_texts, annotated_responses, model, tokenizer\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Trained vectors for {len(emotional_mean_vectors)} categories\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Compute Feature Vectors and Combine with Existing Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_emotional_feature_vectors(mean_vectors_dict, model):\n",
    "    \"\"\"Compute feature vectors by subtracting overall mean from emotional category means\"\"\"\n",
    "    \n",
    "    if \"overall\" not in mean_vectors_dict:\n",
    "        print(\"‚ö†Ô∏è  No overall mean found - cannot compute feature vectors\")\n",
    "        return {}\n",
    "    \n",
    "    feature_vectors = {}\n",
    "    overall_mean = mean_vectors_dict[\"overall\"][\"mean\"]\n",
    "    \n",
    "    emotional_labels = [\"depressive-thinking\", \"anxious-thinking\", \"negative-attribution\", \"pessimistic-projection\"]\n",
    "    \n",
    "    # Create layer-wise feature vectors\n",
    "    num_layers = model.config.num_hidden_layers\n",
    "    hidden_size = model.config.hidden_size\n",
    "    \n",
    "    # Initialize overall mean by layers\n",
    "    feature_vectors[\"overall\"] = torch.zeros(num_layers, hidden_size)\n",
    "    \n",
    "    # Reshape overall mean to layer format (assuming flat vector)\n",
    "    if overall_mean.numel() == hidden_size:\n",
    "        # Single layer mean - replicate across all layers\n",
    "        for layer_idx in range(num_layers):\n",
    "            feature_vectors[\"overall\"][layer_idx] = overall_mean\n",
    "    elif overall_mean.numel() == num_layers * hidden_size:\n",
    "        # Multi-layer mean - reshape\n",
    "        feature_vectors[\"overall\"] = overall_mean.view(num_layers, hidden_size)\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Unexpected overall mean shape: {overall_mean.shape}\")\n",
    "        return {}\n",
    "    \n",
    "    # Compute differential vectors for emotional categories\n",
    "    for label in emotional_labels:\n",
    "        if label in mean_vectors_dict:\n",
    "            label_mean = mean_vectors_dict[label][\"mean\"]\n",
    "            \n",
    "            # Initialize feature vector for this label\n",
    "            feature_vectors[label] = torch.zeros(num_layers, hidden_size)\n",
    "            \n",
    "            # Reshape label mean similar to overall mean\n",
    "            if label_mean.numel() == hidden_size:\n",
    "                for layer_idx in range(num_layers):\n",
    "                    feature_vectors[label][layer_idx] = label_mean - feature_vectors[\"overall\"][layer_idx]\n",
    "            elif label_mean.numel() == num_layers * hidden_size:\n",
    "                label_mean_reshaped = label_mean.view(num_layers, hidden_size)\n",
    "                feature_vectors[label] = label_mean_reshaped - feature_vectors[\"overall\"]\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è  Unexpected {label} mean shape: {label_mean.shape}\")\n",
    "                continue\n",
    "            \n",
    "            print(f\"‚úÖ Computed feature vector for {label}\")\n",
    "    \n",
    "    return feature_vectors\n",
    "\n",
    "# Compute emotional feature vectors\n",
    "print(\"üßÆ Computing emotional feature vectors...\")\n",
    "emotional_feature_vectors = compute_emotional_feature_vectors(emotional_mean_vectors, model)\n",
    "\n",
    "# Combine with existing cognitive vectors if available\n",
    "if existing_vectors and emotional_feature_vectors:\n",
    "    print(\"üîó Combining with existing cognitive vectors...\")\n",
    "    combined_vectors = {**existing_vectors, **emotional_feature_vectors}\n",
    "    print(f\"üì¶ Combined vector set: {list(combined_vectors.keys())}\")\n",
    "elif emotional_feature_vectors:\n",
    "    print(\"üì¶ Using emotional vectors only\")\n",
    "    combined_vectors = emotional_feature_vectors\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No feature vectors available\")\n",
    "    combined_vectors = {}\n",
    "\n",
    "# Save the new vectors\n",
    "if emotional_mean_vectors:\n",
    "    model_id = CONFIG[\"model_name\"].split('/')[-1].lower()\n",
    "    torch.save(\n",
    "        emotional_mean_vectors,\n",
    "        f\"{CONFIG['results_dir']}/data/emotional_mean_vectors_{model_id}_{CONFIG['timestamp']}.pt\"\n",
    "    )\n",
    "    print(f\"üíæ Saved emotional mean vectors\")\n",
    "\n",
    "if combined_vectors:\n",
    "    print(f\"üéØ Ready for emotional steering with {len(combined_vectors)} vector types\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Test Emotional Steering\n",
    "\n",
    "Now we'll test the emotional steering capabilities by generating responses with different emotional steering settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_emotional_steering(model, tokenizer, feature_vectors, test_messages, steering_config):\n",
    "    \"\"\"Test emotional steering across different settings\"\"\"\n",
    "    \n",
    "    results = []\n",
    "    emotional_labels = [\"depressive-thinking\", \"anxious-thinking\", \"negative-attribution\", \"pessimistic-projection\"]\n",
    "    \n",
    "    for msg in tqdm(test_messages, desc=\"Testing emotional steering\"):\n",
    "        message_content = msg[\"content\"]\n",
    "        \n",
    "        # Generate baseline (no steering)\n",
    "        try:\n",
    "            input_ids = tokenizer.encode(message_content, return_tensors=\"pt\")\n",
    "            \n",
    "            with model.generate(\n",
    "                {\"input_ids\": input_ids, \"attention_mask\": (input_ids != tokenizer.pad_token_id).long()},\n",
    "                max_new_tokens=CONFIG[\"max_new_tokens\"],\n",
    "                pad_token_id=tokenizer.pad_token_id\n",
    "            ) as tracer:\n",
    "                baseline_output = model.generator.output.save()\n",
    "            \n",
    "            baseline_text = tokenizer.decode(baseline_output.value[0], skip_special_tokens=True)\n",
    "            input_text = tokenizer.decode(input_ids[0], skip_special_tokens=True)\n",
    "            if baseline_text.startswith(input_text):\n",
    "                baseline_text = baseline_text[len(input_text):].strip()\n",
    "            \n",
    "            baseline_analysis = analyze_emotional_content(baseline_text)\n",
    "            \n",
    "            result_entry = {\n",
    "                \"message\": message_content,\n",
    "                \"baseline_response\": baseline_text,\n",
    "                \"baseline_analysis\": baseline_analysis,\n",
    "                \"steered_responses\": {}\n",
    "            }\n",
    "            \n",
    "            # Test steering for each emotional label\n",
    "            for label in emotional_labels:\n",
    "                if label in feature_vectors and label in steering_config[CONFIG[\"model_name\"]]:\n",
    "                    \n",
    "                    # Test positive steering (enhance emotional pattern)\n",
    "                    try:\n",
    "                        pos_result = generate_and_analyze_emotional(\n",
    "                            model, tokenizer, message_content, \n",
    "                            feature_vectors, steering_config,\n",
    "                            label, \"positive\", CONFIG[\"max_new_tokens\"]\n",
    "                        )\n",
    "                        \n",
    "                        result_entry[\"steered_responses\"][f\"{label}_positive\"] = pos_result\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"Error in positive steering for {label}: {e}\")\n",
    "                    \n",
    "                    # Test negative steering (suppress emotional pattern)\n",
    "                    try:\n",
    "                        neg_result = generate_and_analyze_emotional(\n",
    "                            model, tokenizer, message_content,\n",
    "                            feature_vectors, steering_config,\n",
    "                            label, \"negative\", CONFIG[\"max_new_tokens\"]\n",
    "                        )\n",
    "                        \n",
    "                        result_entry[\"steered_responses\"][f\"{label}_negative\"] = neg_result\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"Error in negative steering for {label}: {e}\")\n",
    "            \n",
    "            results.append(result_entry)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing message: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test on a subset of emotional evaluation messages\n",
    "test_messages = eval_messages[-5:]  # Use last 5 evaluation messages\n",
    "\n",
    "if combined_vectors:\n",
    "    print(\"üß™ Testing emotional steering...\")\n",
    "    steering_results = test_emotional_steering(\n",
    "        model, tokenizer, combined_vectors, test_messages, steering_config\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Completed steering tests for {len(steering_results)} messages\")\n",
    "    \n",
    "    # Save results\n",
    "    with open(f\"{CONFIG['results_dir']}/data/steering_results_{CONFIG['timestamp']}.json\", \"w\") as f:\n",
    "        json.dump(steering_results, f, indent=2)\n",
    "    \n",
    "    print(f\"üíæ Saved steering results\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No feature vectors available for testing\")\n",
    "    steering_results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Analyze and Visualize Results\n",
    "\n",
    "Analyze the effectiveness of emotional steering and create visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_steering_effectiveness(results):\n",
    "    \"\"\"Analyze the effectiveness of emotional steering\"\"\"\n",
    "    \n",
    "    if not results:\n",
    "        print(\"‚ö†Ô∏è  No results to analyze\")\n",
    "        return\n",
    "    \n",
    "    analysis_data = []\n",
    "    \n",
    "    for result in results:\n",
    "        baseline_scores = result[\"baseline_analysis\"]\n",
    "        \n",
    "        # Analyze each steering condition\n",
    "        for steering_type, steered_result in result[\"steered_responses\"].items():\n",
    "            if \"emotional_analysis\" in steered_result:\n",
    "                steered_scores = steered_result[\"emotional_analysis\"]\n",
    "                \n",
    "                label, direction = steering_type.split(\"_\")\n",
    "                \n",
    "                analysis_data.append({\n",
    "                    \"message\": result[\"message\"][:50] + \"...\",\n",
    "                    \"label\": label,\n",
    "                    \"direction\": direction,\n",
    "                    \"baseline_depressive\": baseline_scores[\"depressive_score\"],\n",
    "                    \"steered_depressive\": steered_scores[\"depressive_score\"],\n",
    "                    \"baseline_anxious\": baseline_scores[\"anxious_score\"],\n",
    "                    \"steered_anxious\": steered_scores[\"anxious_score\"],\n",
    "                    \"baseline_negative_attribution\": baseline_scores[\"negative_attribution_score\"],\n",
    "                    \"steered_negative_attribution\": steered_scores[\"negative_attribution_score\"],\n",
    "                    \"baseline_pessimistic\": baseline_scores[\"pessimistic_score\"],\n",
    "                    \"steered_pessimistic\": steered_scores[\"pessimistic_score\"],\n",
    "                    \"baseline_total\": baseline_scores[\"total_emotional_score\"],\n",
    "                    \"steered_total\": steered_scores[\"total_emotional_score\"],\n",
    "                })\n",
    "    \n",
    "    df = pd.DataFrame(analysis_data)\n",
    "    \n",
    "    if len(df) == 0:\n",
    "        print(\"‚ö†Ô∏è  No valid analysis data found\")\n",
    "        return\n",
    "    \n",
    "    # Calculate effectiveness metrics\n",
    "    print(\"üìä Steering Effectiveness Analysis:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Group by label and direction\n",
    "    for label in df[\"label\"].unique():\n",
    "        print(f\"\\nüéØ {label.replace('-', ' ').title()}:\")\n",
    "        \n",
    "        for direction in [\"positive\", \"negative\"]:\n",
    "            subset = df[(df[\"label\"] == label) & (df[\"direction\"] == direction)]\n",
    "            \n",
    "            if len(subset) > 0:\n",
    "                # Calculate score changes\n",
    "                score_col = f\"steered_{label.replace('-', '_')}\"\n",
    "                baseline_col = f\"baseline_{label.replace('-', '_')}\"\n",
    "                \n",
    "                if score_col in subset.columns and baseline_col in subset.columns:\n",
    "                    avg_change = (subset[score_col] - subset[baseline_col]).mean()\n",
    "                    \n",
    "                    expected_change = \"increase\" if direction == \"positive\" else \"decrease\"\n",
    "                    effectiveness = \"‚úÖ\" if (direction == \"positive\" and avg_change > 0) or (direction == \"negative\" and avg_change < 0) else \"‚ùå\"\n",
    "                    \n",
    "                    print(f\"   {direction.title()} steering: {avg_change:.2f} change (expected {expected_change}) {effectiveness}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Analyze results\n",
    "if steering_results:\n",
    "    analysis_df = analyze_steering_effectiveness(steering_results)\n",
    "    \n",
    "    if analysis_df is not None and len(analysis_df) > 0:\n",
    "        # Save analysis\n",
    "        analysis_df.to_csv(f\"{CONFIG['results_dir']}/data/steering_analysis_{CONFIG['timestamp']}.csv\", index=False)\n",
    "        print(f\"\\nüíæ Saved analysis to CSV\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  No analysis data to save\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No steering results available for analysis\")\n",
    "    analysis_df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Create Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_steering_visualizations(analysis_df, results_dir):\n",
    "    \"\"\"Create visualizations of steering effectiveness\"\"\"\n",
    "    \n",
    "    if analysis_df is None or len(analysis_df) == 0:\n",
    "        print(\"‚ö†Ô∏è  No data available for visualization\")\n",
    "        return\n",
    "    \n",
    "    plt.style.use('default')\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    fig.suptitle('Emotional Reasoning Steering Effectiveness', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    emotional_categories = [\n",
    "        ('depressive', 'Depressive Thinking'),\n",
    "        ('anxious', 'Anxious Thinking'),\n",
    "        ('negative_attribution', 'Negative Attribution'),\n",
    "        ('pessimistic', 'Pessimistic Projection')\n",
    "    ]\n",
    "    \n",
    "    for idx, (category, title) in enumerate(emotional_categories):\n",
    "        ax = axes[idx // 2, idx % 2]\n",
    "        \n",
    "        # Filter data for this category\n",
    "        category_data = analysis_df[analysis_df['label'] == category.replace('_', '-')]\n",
    "        \n",
    "        if len(category_data) == 0:\n",
    "            ax.text(0.5, 0.5, f'No data for\\n{title}', \n",
    "                   ha='center', va='center', transform=ax.transAxes, fontsize=12)\n",
    "            ax.set_title(title)\n",
    "            continue\n",
    "        \n",
    "        # Prepare data for plotting\n",
    "        baseline_col = f'baseline_{category}'\n",
    "        steered_col = f'steered_{category}'\n",
    "        \n",
    "        if baseline_col in category_data.columns and steered_col in category_data.columns:\n",
    "            pos_data = category_data[category_data['direction'] == 'positive']\n",
    "            neg_data = category_data[category_data['direction'] == 'negative']\n",
    "            \n",
    "            x_pos = np.arange(len(pos_data))\n",
    "            width = 0.35\n",
    "            \n",
    "            if len(pos_data) > 0:\n",
    "                ax.bar(x_pos - width/2, pos_data[baseline_col], width, \n",
    "                      label='Baseline', alpha=0.7, color='gray')\n",
    "                ax.bar(x_pos + width/2, pos_data[steered_col], width,\n",
    "                      label='Positive Steering', alpha=0.7, color='red')\n",
    "            \n",
    "            if len(neg_data) > 0:\n",
    "                x_neg = np.arange(len(pos_data), len(pos_data) + len(neg_data))\n",
    "                ax.bar(x_neg - width/2, neg_data[baseline_col], width,\n",
    "                      alpha=0.7, color='gray')\n",
    "                ax.bar(x_neg + width/2, neg_data[steered_col], width,\n",
    "                      label='Negative Steering', alpha=0.7, color='blue')\n",
    "            \n",
    "            ax.set_title(title)\n",
    "            ax.set_ylabel('Emotional Score (%)')\n",
    "            ax.legend()\n",
    "            ax.grid(True, alpha=0.3)\n",
    "        else:\n",
    "            ax.text(0.5, 0.5, f'Data columns missing\\nfor {title}', \n",
    "                   ha='center', va='center', transform=ax.transAxes, fontsize=12)\n",
    "            ax.set_title(title)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{results_dir}/figures/emotional_steering_effectiveness_{CONFIG[\"timestamp\"]}.png', \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Create summary heatmap\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Calculate average changes for heatmap\n",
    "    heatmap_data = []\n",
    "    labels = []\n",
    "    \n",
    "    for category, title in emotional_categories:\n",
    "        category_label = category.replace('_', '-')\n",
    "        pos_data = analysis_df[(analysis_df['label'] == category_label) & \n",
    "                              (analysis_df['direction'] == 'positive')]\n",
    "        neg_data = analysis_df[(analysis_df['label'] == category_label) & \n",
    "                              (analysis_df['direction'] == 'negative')]\n",
    "        \n",
    "        baseline_col = f'baseline_{category}'\n",
    "        steered_col = f'steered_{category}'\n",
    "        \n",
    "        pos_change = 0\n",
    "        neg_change = 0\n",
    "        \n",
    "        if len(pos_data) > 0 and baseline_col in pos_data.columns:\n",
    "            pos_change = (pos_data[steered_col] - pos_data[baseline_col]).mean()\n",
    "        \n",
    "        if len(neg_data) > 0 and baseline_col in neg_data.columns:\n",
    "            neg_change = (neg_data[steered_col] - neg_data[baseline_col]).mean()\n",
    "        \n",
    "        heatmap_data.append([pos_change, neg_change])\n",
    "        labels.append(title)\n",
    "    \n",
    "    if heatmap_data:\n",
    "        sns.heatmap(heatmap_data, \n",
    "                   xticklabels=['Positive Steering', 'Negative Steering'],\n",
    "                   yticklabels=labels,\n",
    "                   annot=True, fmt='.2f', cmap='RdBu_r', center=0,\n",
    "                   cbar_kws={'label': 'Average Score Change (%)'})\n",
    "        \n",
    "        plt.title('Emotional Steering Effectiveness Heatmap', fontweight='bold', pad=20)\n",
    "        plt.xlabel('Steering Direction')\n",
    "        plt.ylabel('Emotional Category')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{results_dir}/figures/emotional_steering_heatmap_{CONFIG[\"timestamp\"]}.png', \n",
    "                    dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    print(f\"üìä Visualizations saved to {results_dir}/figures/\")\n",
    "\n",
    "# Create visualizations\n",
    "if analysis_df is not None:\n",
    "    create_steering_visualizations(analysis_df, CONFIG[\"results_dir\"])\n",
    "else:\n",
    "    print(\"üìä Skipping visualizations - no analysis data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Example Usage and Demo\n",
    "\n",
    "Demonstrate how to use the emotional steering system with specific examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo_emotional_steering(model, tokenizer, feature_vectors, steering_config):\n",
    "    \"\"\"Demonstrate emotional steering with examples\"\"\"\n",
    "    \n",
    "    if not feature_vectors:\n",
    "        print(\"‚ö†Ô∏è  No feature vectors available for demo\")\n",
    "        return\n",
    "    \n",
    "    demo_messages = [\n",
    "        \"You've been working on a creative project, but it's not turning out as you hoped. How do you feel about your creative abilities?\",\n",
    "        \"You have an important presentation tomorrow. What thoughts are going through your mind?\",\n",
    "        \"You received some constructive feedback on your work. How do you interpret this feedback?\"\n",
    "    ]\n",
    "    \n",
    "    emotional_labels = [\"depressive-thinking\", \"anxious-thinking\", \"negative-attribution\"]\n",
    "    \n",
    "    print(\"üé≠ Emotional Steering Demo\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for i, message in enumerate(demo_messages[:len(emotional_labels)]):\n",
    "        label = emotional_labels[i]\n",
    "        \n",
    "        if label not in feature_vectors or label not in steering_config[CONFIG[\"model_name\"]]:\n",
    "            print(f\"‚ö†Ô∏è  Skipping {label} - vectors not available\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nüìù Message {i+1}: {message}\")\n",
    "        print(f\"üéØ Demonstrating {label.replace('-', ' ').title()} steering\")\n",
    "        \n",
    "        try:\n",
    "            # Baseline response\n",
    "            input_ids = tokenizer.encode(message, return_tensors=\"pt\")\n",
    "            \n",
    "            with model.generate(\n",
    "                {\"input_ids\": input_ids, \"attention_mask\": (input_ids != tokenizer.pad_token_id).long()},\n",
    "                max_new_tokens=200,\n",
    "                pad_token_id=tokenizer.pad_token_id\n",
    "            ) as tracer:\n",
    "                baseline_output = model.generator.output.save()\n",
    "            \n",
    "            baseline_text = tokenizer.decode(baseline_output.value[0], skip_special_tokens=True)\n",
    "            input_text = tokenizer.decode(input_ids[0], skip_special_tokens=True)\n",
    "            if baseline_text.startswith(input_text):\n",
    "                baseline_text = baseline_text[len(input_text):].strip()\n",
    "            \n",
    "            print(f\"\\nüîµ Baseline Response:\")\n",
    "            print(f\"   {baseline_text[:300]}...\")\n",
    "            \n",
    "            baseline_analysis = analyze_emotional_content(baseline_text)\n",
    "            print(f\"   Emotional Score: {baseline_analysis['total_emotional_score']:.1f}%\")\n",
    "            \n",
    "            # Positive steering (enhance emotional pattern)\n",
    "            pos_result = generate_and_analyze_emotional(\n",
    "                model, tokenizer, message, feature_vectors, steering_config,\n",
    "                label, \"positive\", 200\n",
    "            )\n",
    "            \n",
    "            print(f\"\\nüî¥ Enhanced {label.replace('-', ' ').title()}:\")\n",
    "            print(f\"   {pos_result['response'][:300]}...\")\n",
    "            print(f\"   Emotional Score: {pos_result['emotional_analysis']['total_emotional_score']:.1f}%\")\n",
    "            \n",
    "            # Negative steering (suppress emotional pattern)\n",
    "            neg_result = generate_and_analyze_emotional(\n",
    "                model, tokenizer, message, feature_vectors, steering_config,\n",
    "                label, \"negative\", 200\n",
    "            )\n",
    "            \n",
    "            print(f\"\\nüü¢ Suppressed {label.replace('-', ' ').title()}:\")\n",
    "            print(f\"   {neg_result['response'][:300]}...\")\n",
    "            print(f\"   Emotional Score: {neg_result['emotional_analysis']['total_emotional_score']:.1f}%\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error in demo: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"\\n‚úÖ Demo completed!\")\n",
    "\n",
    "# Run demo\n",
    "if combined_vectors:\n",
    "    demo_emotional_steering(model, tokenizer, combined_vectors, steering_config)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Demo skipped - no feature vectors available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Safety and Ethical Considerations\n",
    "\n",
    "Document important safety considerations and ethical guidelines for this research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_safety_report():\n",
    "    \"\"\"Generate a safety and ethics report for emotional steering research\"\"\"\n",
    "    \n",
    "    report = f\"\"\"\n",
    "# Emotional Reasoning Steering - Safety and Ethics Report\n",
    "\n",
    "**Generated on:** {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\n",
    "**Model:** {CONFIG['model_name']}\n",
    "**Research Session ID:** {CONFIG['timestamp']}\n",
    "\n",
    "## Safety Considerations\n",
    "\n",
    "### 1. Research-Only Use\n",
    "- This implementation is designed exclusively for research purposes\n",
    "- Should NOT be deployed in production systems without extensive safety testing\n",
    "- Requires institutional review board (IRB) approval for human subjects research\n",
    "\n",
    "### 2. Potential Risks\n",
    "- **Psychological Harm**: Steering toward negative emotional states could be harmful\n",
    "- **Misuse**: Could be used to manipulate users or create harmful content\n",
    "- **Bias Amplification**: May amplify existing biases in training data\n",
    "- **Unintended Effects**: Steering may have unpredictable side effects\n",
    "\n",
    "### 3. Required Safeguards\n",
    "- **Informed Consent**: Users must know when emotional steering is active\n",
    "- **Monitoring**: Continuous monitoring for harmful outputs\n",
    "- **Reversibility**: Always provide countermeasures (negative steering)\n",
    "- **Access Controls**: Restrict access to authorized researchers only\n",
    "- **Documentation**: Maintain detailed logs of all experiments\n",
    "\n",
    "## Ethical Guidelines\n",
    "\n",
    "### 1. Beneficence\n",
    "- Research should aim to benefit society and advance scientific knowledge\n",
    "- Potential applications in mental health research and AI safety\n",
    "- Must not cause unnecessary harm to participants or society\n",
    "\n",
    "### 2. Autonomy\n",
    "- Respect user autonomy and decision-making capacity\n",
    "- Provide clear information about emotional steering effects\n",
    "- Allow users to opt-out at any time\n",
    "\n",
    "### 3. Justice\n",
    "- Ensure fair distribution of research benefits and risks\n",
    "- Consider impacts on vulnerable populations\n",
    "- Avoid discriminatory or biased applications\n",
    "\n",
    "### 4. Non-maleficence\n",
    "- \"Do no harm\" - minimize risks to participants and society\n",
    "- Implement robust safety measures\n",
    "- Have emergency stop procedures in place\n",
    "\n",
    "## Recommended Usage Protocols\n",
    "\n",
    "### 1. Before Starting Research\n",
    "- Obtain IRB approval for human subjects research\n",
    "- Develop comprehensive safety protocols\n",
    "- Train all research staff on ethical considerations\n",
    "- Establish data security and privacy protections\n",
    "\n",
    "### 2. During Research\n",
    "- Monitor all outputs for harmful content\n",
    "- Maintain detailed experimental logs\n",
    "- Provide psychological support resources to participants\n",
    "- Regular safety reviews and protocol updates\n",
    "\n",
    "### 3. After Research\n",
    "- Secure deletion of sensitive data\n",
    "- Debrief participants about the research\n",
    "- Report findings responsibly to scientific community\n",
    "- Consider long-term societal implications\n",
    "\n",
    "## Technical Safety Measures\n",
    "\n",
    "### 1. Content Filtering\n",
    "- Implement automated content filtering for harmful outputs\n",
    "- Human review of all research outputs\n",
    "- Real-time monitoring of emotional intensity\n",
    "\n",
    "### 2. Access Controls\n",
    "- Multi-factor authentication for system access\n",
    "- Role-based permissions for different user types\n",
    "- Audit logs of all system interactions\n",
    "\n",
    "### 3. Data Security\n",
    "- Encryption of all research data\n",
    "- Secure storage with limited access\n",
    "- Regular security audits and updates\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Emotional reasoning steering is a powerful research tool that requires careful ethical consideration and robust safety measures. This research should only be conducted by qualified researchers with appropriate oversight and safeguards in place.\n",
    "\n",
    "For questions about this research or to report safety concerns, please contact the research team immediately.\n",
    "\"\"\"\n",
    "    \n",
    "    return report\n",
    "\n",
    "# Generate and save safety report\n",
    "safety_report = generate_safety_report()\n",
    "\n",
    "with open(f\"{CONFIG['results_dir']}/safety_ethics_report_{CONFIG['timestamp']}.md\", \"w\") as f:\n",
    "    f.write(safety_report)\n",
    "\n",
    "print(\"üõ°Ô∏è Safety and Ethics Report Generated\")\n",
    "print(\"=\" * 50)\n",
    "print(safety_report)\n",
    "print(f\"\\nüíæ Full report saved to: {CONFIG['results_dir']}/safety_ethics_report_{CONFIG['timestamp']}.md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "This notebook has provided a complete implementation of emotional reasoning steering for language models. Here's what we accomplished:\n",
    "\n",
    "### ‚úÖ Completed Tasks:\n",
    "1. **Extended the COT-steering framework** to include emotional reasoning categories\n",
    "2. **Generated training data** with emotionally-charged prompts\n",
    "3. **Trained steering vectors** for depressive, anxious, negative attribution, and pessimistic thinking patterns\n",
    "4. **Implemented steering functions** to enhance or suppress emotional patterns\n",
    "5. **Created evaluation metrics** to measure emotional content in responses\n",
    "6. **Tested the system** with various emotional steering configurations\n",
    "7. **Generated visualizations** to analyze steering effectiveness\n",
    "8. **Documented safety and ethical considerations**\n",
    "\n",
    "### üî¨ Research Applications:\n",
    "- **Mental Health Research**: Understanding how AI models represent emotional states\n",
    "- **Bias Detection**: Identifying problematic thinking patterns in AI outputs\n",
    "- **Therapeutic AI**: Training models to recognize and counter negative thought patterns\n",
    "- **Content Moderation**: Detecting and filtering emotionally harmful content\n",
    "- **AI Safety**: Understanding and controlling emotional biases in language models\n",
    "\n",
    "### ‚ö†Ô∏è Important Reminders:\n",
    "- This is a **research tool only** - not for production use\n",
    "- Requires **ethical oversight** and **IRB approval** for human subjects research\n",
    "- Must include **safety safeguards** and **continuous monitoring**\n",
    "- Should always provide **positive counterbalancing** capabilities\n",
    "\n",
    "### üöÄ Next Steps:\n",
    "1. **Expand training data** with more diverse emotional prompts\n",
    "2. **Fine-tune steering coefficients** for optimal effectiveness\n",
    "3. **Implement real-time safety monitoring** systems\n",
    "4. **Conduct longitudinal studies** on steering effectiveness\n",
    "5. **Develop therapeutic applications** with proper clinical oversight\n",
    "6. **Create automated bias detection** systems for production AI\n",
    "\n",
    "Remember to use this technology responsibly and always prioritize user safety and well-being in your research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary of all generated files\n",
    "print(\"üìÅ Generated Files Summary\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "files_generated = [\n",
    "    f\"Data files in {CONFIG['results_dir']}/data/:\",\n",
    "    f\"  - emotional_annotations_{CONFIG['timestamp']}.json\",\n",
    "    f\"  - emotional_mean_vectors_{CONFIG['model_name'].split('/')[-1].lower()}_{CONFIG['timestamp']}.pt\",\n",
    "    f\"  - steering_results_{CONFIG['timestamp']}.json\",\n",
    "    f\"  - steering_analysis_{CONFIG['timestamp']}.csv\",\n",
    "    f\"\",\n",
    "    f\"Visualization files in {CONFIG['results_dir']}/figures/:\",\n",
    "    f\"  - emotional_steering_effectiveness_{CONFIG['timestamp']}.png\",\n",
    "    f\"  - emotional_steering_heatmap_{CONFIG['timestamp']}.png\",\n",
    "    f\"\",\n",
    "    f\"Documentation files in {CONFIG['results_dir']}/:\",\n",
    "    f\"  - safety_ethics_report_{CONFIG['timestamp']}.md\",\n",
    "]\n",
    "\n",
    "for file_info in files_generated:\n",
    "    print(file_info)\n",
    "\n",
    "print(f\"\\nüéâ Emotional Reasoning Steering Implementation Complete!\")\n",
    "print(f\"üìä Session ID: {CONFIG['timestamp']}\")\n",
    "print(f\"ü§ñ Model: {CONFIG['model_name']}\")\n",
    "print(f\"üìÖ Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
